{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvWQ-3BZxV_f"
      },
      "outputs": [],
      "source": [
        "! pip install -q --upgrade google-generativeai langchain-google-genai python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9KvVQvlxaFp"
      },
      "outputs": [],
      "source": [
        "!echo -e 'GOOGLE_API_KEY=AIzaSyBhah77AspnXGB_1JgodpJog4ShEXCgZbo' > .env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AD-oF5VxfHH",
        "outputId": "f71157e7-68be-466d-8ee0-547aee9b0e92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6ZQrlkexl0_"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RcsLQSCxvFf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "genai.configure(api_key=os.environ.get(\"GOOGLE_API_KEY\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUnYY1WEcDNT"
      },
      "outputs": [],
      "source": [
        "# response = model.generate_content(\n",
        "#     contents=history,\n",
        "#     generation_config=generation_config,\n",
        "#     timeout=120,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOW5t6D1xyxn"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmNHGUdDx6je"
      },
      "outputs": [],
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGGRRz55dEGD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyfHWCHhx9KM"
      },
      "outputs": [],
      "source": [
        "result = llm.invoke(\"Who is the PM of Nepal?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2IGBckkyMyl"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "import textwrap\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "68Y1bNNsyAcl",
        "outputId": "bc92c1c7-3ca5-42b8-ca0f-ca964c792ae0"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": "> Pushpa Kamal Dahal (also known as Prachanda)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "to_markdown(result.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlb6dg2fyGK5",
        "outputId": "0d4a2910-5868-46af-a790-5ad9823a0be2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "libtesseract-dev is already the newest version (4.1.1-2.1build1).\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.352)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.6)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.3)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.70 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.75)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!sudo apt -y -qq install tesseract-ocr libtesseract-dev\n",
        "\n",
        "!sudo apt-get -y -qq install poppler-utils libxml2-dev libxslt1-dev antiword unrtf poppler-utils pstotext tesseract-ocr flac ffmpeg lame libmad0 libsox-fmt-mp3 sox libjpeg-dev swig\n",
        "\n",
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_vnnZXWyruh"
      },
      "outputs": [],
      "source": [
        "import urllib\n",
        "import warnings\n",
        "from pathlib import Path as p\n",
        "from pprint import pprint\n",
        "\n",
        "import pandas as pd\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "# warnings.filterwarnings(\"ignore\")\n",
        "# # restart python kernal if issues with langchain import."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlD7MXgUzWyD",
        "outputId": "c2558a3f-61c9-493a-9738-b520ae4b9a25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (3.17.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X37uD3gNy1zA"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D21BU4NVy9ye"
      },
      "outputs": [],
      "source": [
        "model = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
        "                             temperature=0.3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3G91_8EdkL9"
      },
      "outputs": [],
      "source": [
        "# response = model.generate_content(\n",
        "#     contents=history,\n",
        "#     generation_config=generation_config,\n",
        "#     timeout=120,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_DfffuFzAPC",
        "outputId": "fb9610ff-27c2-4f19-8940-56cf49fcc9bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------------------------------------------------------------------- -------------  \n",
            "By Bhupendra Singh Saud  ADBMS   3 \n",
            " Unit 1  \n",
            "Theoretical Concept of overall database  \n",
            "Data   \n",
            "The collection of raw facts is called data.  \n",
            " \n",
            "File \n",
            "A file is the collection of related groups of data for example, payroll file of a company consists of \n",
            "the salary detail and all of these records have the same heads (e.g.; basic pay, HRA, FA etc.).  \n",
            " \n",
            "Records  \n",
            "A file may be further divided into more descriptive subdivisions, called, records.    In other words \n",
            "a record is a collection of relat ed data items as a single unit. It is also called co lumn of table.  \n",
            " \n",
            "Tuples  \n",
            "The row of a table is called tuples.  It is also called value of a table.  \n",
            " \n",
            "Fields  \n",
            "The column of a table is called fields.  \n",
            " \n",
            "Database  \n",
            "A database is a collection of related data necessary to manage an organization. By data, we mean \n",
            "known  facts that can be recorded and have implicit meaning. For example, consider names, \n",
            "telephone numbers and addresses of the people. We may have recorded this data in an indexed \n",
            "address book, or we may have recorded on the hard drive, using a personal comput er and software \n",
            "such as MS -Access, or Excel. This is the collection of related data with an implicit meaning and \n",
            "hence is a database. A database is logically coherent collection of data with some inherent \n",
            "meaning. A database is designed, built and populate d with data for specific purpose.  It excludes \n",
            "transient data such as: input documents, reports and intermediate results obtained during \n",
            "processing.  \n",
            " \n",
            "DBMS  \n",
            "A database management system is a set of procedures that manages the database and provide \n",
            "access to t he database in the form required by any application program. It effectively ensures that \n",
            "necessary data in the desired form is available for diverse applications for different departments in \n",
            "an organization. A DBMS is hence a general purpose software syste m that facilitates the processes\n"
          ]
        }
      ],
      "source": [
        "pdf_loader = PyPDFLoader('/content/db.pdf')\n",
        "try:\n",
        "  pages = pdf_loader.load_and_split()\n",
        "\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "  clean_pages = None\n",
        "\n",
        "if pages:\n",
        "  print(pages[2].page_content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08jc0VrqUyRH",
        "outputId": "fdc9913e-d59b-41ae-b550-7fb3c491f6e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK_wPOlHUJ0C",
        "outputId": "c7616a4c-3ce3-4f44-c707-c7c0387d1556"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unit 1.pdf\n",
            "unit 2.pdf\n",
            "unit 3.pdf\n",
            "unit 4.pdf\n",
            "unit 5.pdf\n",
            "unit 6.pdf\n",
            "unit 7.pdf\n",
            "unit 8.pdf\n",
            "Downloaded From: csitascolhelp\n",
            "Notes By: Lecturer Ganesh\n",
            "1 \n",
            " \n",
            "RTS \n",
            " Chapter 1  \n",
            "Introduction  \n",
            "REAL -TIME SYSTEM  \n",
            "Real-time systems have been defined as: \"those systems in which the correctness of the system \n",
            "depends not only on the logical result of the computation, but also on the time at which the \n",
            "results are produced” .  \n",
            "REAL -TIME CHARACTERISTICS  \n",
            "It‟s convenient to divide a real -time system into three components: the controlling system  , \n",
            "controlled  system and environment . \n",
            "– avionics computer (controller) controls aircraft system (controlled) to maintain \n",
            "desirable flight (environ ment) characteristics  \n",
            "– desktop computer (controller) buffers, decodes and displays video streams \n",
            "(controlled) and adapts in response to unreliable data delivery of encoded data \n",
            "(environment)  \n",
            "Timing constraints  are placed on the controlling system and its in teractions with the controlled \n",
            "system, in response to changes in the environment. Hard and soft constraints.  \n",
            "– Hard constraints: missing a deadline is considered catastrophic  \n",
            "– Soft constraints: missing deadline is not considered to be fatal, result may have \n",
            "diminishing value with time.  \n",
            "  \n",
            "Fig Typical Real time System\n",
            "2 \n",
            " \n",
            "RTS \n",
            " REAL -TIME SYSTEM APPLICATION DOMAINS  \n",
            "Potential uses for real -time systems include but are not limited to:  \n",
            "• Telecommunication systems  \n",
            "• Automotive control  \n",
            "• Multimedia servers and workstations  \n",
            "• Signal processing systems  \n",
            "• Radar systems  \n",
            "• Consumer electronics  \n",
            "• Process control  \n",
            "• Automated manufacturing systems  \n",
            "• Supervisory control and data acquisition (SCADA) systems  \n",
            "• Electrical utilities  \n",
            "• Semiconductor fabrication systems  \n",
            "• Defense systems  \n",
            "• Avionics  \n",
            "• Air traffic control  \n",
            "• Autonomous navigation systems  \n",
            "• Vehicle control systems  \n",
            "• Transportation and traffic control systems  \n",
            "• Satellite systems  \n",
            "• Nuclear power control systems  \n",
            " \n",
            "DIGITAL CONTROL  \n",
            "They are  the simplest and the most deterministic real -time applications. They also have the most \n",
            "stringent  timing requirements.  Many real -time systems are embedded in sensors and actuators \n",
            "and function as digital controllers.  Figure 1 –1 shows such a system. The term plant in the block \n",
            "diagram refers to a  controlled system, for example, an engine, a brake, an aircraft, a patient. The \n",
            "state of the plant  is monitored by sensors and can be changed by actuators. The real -time \n",
            "(computing) system  estimates from the sensor readings the current state of the plant and \n",
            "computes a control output  based on the difference between the current state and the desired state \n",
            "(called reference input  in the figure). We call this computation the control -law computation of\n",
            "3 \n",
            " \n",
            "RTS \n",
            " the controller. The  output thus generated activates the actuators, which bring the plant closer to \n",
            "the desired state.  \n",
            "A simple example :  As an example, we consider an analog single -input/single -output PID \n",
            "(Proportional, Integral, and Derivative) controller. This simple kind of controller is commonly \n",
            "used in pra ctice. The analog sensor reading y(t) gives the measured state of the plant at time t. \n",
            "Let e(t) = r (t) − y(t) denote the difference between the desired state r (t) and the measured state \n",
            "y(t) at time t . The output u(t) of the controller consists of three  terms: a term that is proportional \n",
            "to e(t), a term that is proportional to the integral of e(t) and a term that is proportional to the \n",
            "derivative of e(t). \n",
            " \n",
            "HIGH LEVEL CONTROLS : \n",
            "Controllers in a complex monitor and control system are typically organized h ierarchically.  One \n",
            "or more digital controllers at the lowest level directly control the physical plant. Each  output of a \n",
            "higher -level controller is a reference input of one or more lower -level controllers.  With few \n",
            "exceptions, one or more of the higher -level controllers interfaces with the operator(s).  \n",
            "Examples of Control Hierarchy :\n",
            "4 \n",
            " \n",
            "RTS \n",
            " For example, a patient care system may consist of microprocessor -based controllers that monitor  \n",
            "and control the patient‟s blood pressure, respiration, glucose, and so forth. There may be  a \n",
            "higher -level controller (e.g., an expert system) which interacts with the operator (a nurse  or \n",
            "doctor) and chooses the desired values of these health indicators. While the computation  done by \n",
            "each digital controller is simple and near ly deterministic, the computation of a high  level  \n",
            "controller is likely to be far more complex and variable. While the period of a low  level  control -\n",
            "law computation ranges from milliseconds to seconds, the periods of high -level  control -law \n",
            "computations may be minutes, even hours.  \n",
            "Next example is as:  \n",
            " \n",
            " \n",
            " \n",
            "shows a more complex example: the hierarchy of flight control, avionics,  and air traffic control \n",
            "systems.5 The Air Traffic Control (ATC) system is at the highest level. It  regulates the flow of \n",
            "flights to each destination airport. It does so by assigning to each aircraft  an arrival time at each \n",
            "metering fix6 (or waypoint) en route to the destination: The aircraft is  supposed to arrive at the \n",
            "metering fix at the assigned arrival time. At any time while in fl ight, the assigned arrival time to \n",
            "the next metering fix is a reference input to the on -board flight  management system. The flight \n",
            "management system chooses a time -referenced flight path  that brings the aircraft to the next \n",
            "metering fix at the assigned arr ival time. The cruise speed,  turn radius, decent/accent rates, and\n",
            "5 \n",
            " \n",
            "RTS \n",
            " so forth required to follow the chosen time -referenced  flight path are the reference inputs to the \n",
            "flight controller at the lowest level of the control  hierarchy.  \n",
            "GUIDANCE AND CONTROL:  \n",
            "While a digital controller deals with some dynamical behavior of the physical plant, a second  \n",
            "level  controller typically performs guidance and path planning functions to achieve a higher  level \n",
            "goal. In particular, it tries to find one of the most desirable  trajectories among all  trajectories that \n",
            "meet the constraints of the system. The trajectory is most desirable because it  optimizes some \n",
            "cost function(s). The algorithm(s) used for this purpose is the solution(s) of  some constrained \n",
            "optimization problem(s) . \n",
            "As an example, we look again at a flight management system. The constraints that must  be \n",
            "satisfied by the chosen flight path include the ones imposed by the characteristics of the  aircraft, \n",
            "such as the maximum and minimum allowed cruise speeds and decent /accent rates, as  well as \n",
            "constraints imposed by external factors, such as the ground track and altitude profile  specified by \n",
            "the ATC system and weather conditions. A cost function is fuel consumption: A  most desirable \n",
            "flight path is a most fuel efficient among all paths that meet all the constraints  and will bring the \n",
            "aircraft to the next metering fix at the assigned arrival time. This problem  is known as the \n",
            "constrained fixed -time, minimum -fuel problem. When the flight is late, the  flight management \n",
            "syste m may try to bring the aircraft to the next metering fix in the shortest  time. In that case, it \n",
            "will use an algorithm that solves the time -optimal problem.   \n",
            "REAL -TIME COMMAND AND CONTROL  \n",
            "The controller at the highest level of a control hierarchy is a command and control system. An \n",
            "Air Traffic Control (ATC) system is an excellent example. Figure 1 –5 shows a possible \n",
            "architecture. The ATC system monitors the aircraft in its coverage area and the environment (e.g, \n",
            "weather condition) and generates and pres ents the information needed by the operators (i.e., the \n",
            "air traffic controllers). Outputs from the ATC system include the assigned arrival times to \n",
            "metering fixes for individual aircraft. As stated earlier, these outputs are reference inputs to on -\n",
            "board fl ight management systems. Thus, the ATC system indirectly controls the  embedded \n",
            "components in low levels of the control hierarchy. In addition, the ATC system provides voice\n",
            "6 \n",
            " \n",
            "RTS \n",
            " and telemetry links to on -board avionics. Thus it supports the communication among the \n",
            "operators at both levels (i.e., the pilots and air traffic controllers).  \n",
            "The ATC system gathers information on the “state” of each aircraft via one or more active \n",
            "radars. Such a radar interrogates each aircraft periodically. When interrogated, an air - craft \n",
            "responds by sending to the ATC system its “state variables”: identifier, position, altitude, \n",
            "heading, and so on. (In Figure 1 –5, these variables are referred to collectively as a track record, \n",
            "and the current trajectory of the aircraft is a track.) T he ATC system processes messages from \n",
            "aircraft and stores the state information thus obtained in a database. This information is picked \n",
            "up and processed by display processors. At the same time, a surveillance system continuously \n",
            "analyzes the scenario and a lerts the operators whenever it detects any potential hazard (e.g., a \n",
            "possible collision). Again, the rates at which human interfaces (e.g., keyboards and displays) \n",
            "operate must be at least 10 Hz. The other response times can be considerably larger. For \n",
            "example, the allowed response time from radar inputs is one to two seconds, and the period of \n",
            "weather updates is in the order of ten seconds. From this example, we can see that a command \n",
            "and control system bears little resemblance to low -level controllers. I n contrast to a low -level \n",
            "controller whose workload is either purely or mostly periodic, a command and control system \n",
            "also computes and communicates in response to sporadic events and operators‟ commands. \n",
            "Furthermore, it may process image and speech, query  and update databases, simulate various \n",
            "scenarios, and the like. The resource and processing time demands of these tasks can be large \n",
            "and varied. Fortunately, most of the timing requirements of a command and control system are \n",
            "less stringent. Whereas a low -level control system typically runs on one computer or a few \n",
            "computers connected by a small network or dedicated links, a command and control system is \n",
            "often a large distributed system containing tens and hundreds of computers and many different \n",
            "kinds of networks. In this respect, it resembles interactive, on -line transaction systems (e.g., a \n",
            "stock price quotation system) which are also sometimes called real -time systems.\n",
            "7 \n",
            " \n",
            "RTS \n",
            "  \n",
            "Fig. Architecture of Air Traffic Control System  \n",
            "Radar Signal processing\n",
            "8 \n",
            " \n",
            "RTS \n",
            "  \n",
            "Fig . Radar Signal processing and Tracking System  \n",
            "The Radar signal processing system consists of an Input/Output (I/O) subsystem that samples \n",
            "and digitizes the echo signal  from the radar and places the sampled values in a shared memory. \n",
            "An array of digital signa l processors processes these sampled values. The data thus produced are \n",
            "analyzed by one or  more data processors, which not only interface with the display system, but \n",
            "also generate  commands to control the radar and select parameters to be used by signal \n",
            "processors in the  next cycle of data collection and analysis.  \n",
            "How signal processing is done?  \n",
            "To search for objects of interest in its coverage area, the  radar scans the area by pointing its \n",
            "antenna in one direction at a time. During the time the  antenna dwel ls in a direction, it first sends \n",
            "a short radio frequency pulse. It then collects and  examines the echo signal returning to the \n",
            "antenna.  The echo signal consists solely of background noise if the transmitted pulse does not hit  \n",
            "any object. On the other hand , if there is a reflective object (e.g., an airplane or storm cloud)  at a \n",
            "distance x meters from the antenna, the echo signal reflected by the object returns to the  antenna\n",
            "9 \n",
            " \n",
            "RTS \n",
            " at approximately 2 x/c seconds after the transmitted pulse, where c = 3×108 meters  per second is \n",
            "the speed of light. The echo signal collected at this time should be stronger than  when there is no \n",
            "reflected signal. If the object is moving, the frequency of the reflected signal is  no longer equal \n",
            "to that of the transmitted pulse. The amou nt of frequency shift (called Doppler  shift) is \n",
            "proportional to the velocity of the object. Therefore, by examining the strength and  frequency \n",
            "spectrum of the echo signal, the system can determine whether there are objects  in the direction \n",
            "pointed at by th e antenna and if there are objects, what their positions and  velocities are.  \n",
            "BASIC TERMS USED IN RADAR SIGNAL PROCESSING:  \n",
            "TRACKING  \n",
            "Strong noise and man -made interferences, including electronic counter  measure (i.e., jamming), \n",
            "can lead the signal processing  and detection process to wrong conclusions  about the presence of \n",
            "objects. A track record on a non  existing object is called a false  return.  \n",
            "An application that examines all the track records in order to sort out false returns from  real ones \n",
            "and update th e trajectories of detected objects is called a tracker . Using the jargon  of the subject \n",
            "area, we say that the tracker assigns each measured value (i.e., the tuple of position  and velocity \n",
            "contained in each of the track records generated in a scan) to a tra jectory.  \n",
            "If the trajectory is an existing one, the measured value assigned to it gives the current position  \n",
            "and velocity of the object moving along the trajectory. If the trajectory is new, the measured  \n",
            "value gives the position and velocity of a possible new object.   \n",
            "GATING  \n",
            "Typically, tracking is carried out in two steps: gating and data association . Gating is the process \n",
            "of putting each measured value into one of two categories depending  on whether it can or cannot \n",
            "be tentatively assigned to one or more e stablished trajectories.  \n",
            "The gating process tentatively assigns a measured value to an established trajectory  if it is within \n",
            "a threshold distance G away from the predicted current position and velocity  of the object \n",
            "moving along the trajectory. (Below, we  call the distance between the measured  and predicted \n",
            "values the distance of the assignment.) The threshold G is called the track gate.  It is chosen so\n",
            "10 \n",
            " \n",
            "RTS \n",
            " that the probability of a valid measured value falling in the region bounded by  a sphere of radius \n",
            "G centered around a predicted value is a desired constant . \n",
            " \n",
            "Fig . Gating Process  \n",
            " \n",
            "DATA ASSOCIATION:  \n",
            "The tracking process completes if, after gating, every measured  value is assigned to at most one \n",
            "trajectory and every trajectory is assigned at most one measured  value. This is likely to be case \n",
            "when (1) the radar signal is strong and interference is  low (and hence false returns are few) and \n",
            "(2) the density of objects is low. Under adverse conditions,  the assignment produced by gating \n",
            "may be ambiguous, tha t is, some measured value  is assigned to more than one trajectory or a \n",
            "trajectory is assigned more than one measured  value. The data association step is then carried out \n",
            "to complete the assignments and resolve  ambiguities.  \n",
            "OTHER REAL -TIME APPLICATIONS:  \n",
            "Two most common real -time applications are real-time databases and multimedia applications . \n",
            " \n",
            "REAL -TIME DATABASES:\n",
            "11 \n",
            " \n",
            "RTS \n",
            " The term real -time database systems refers to a diverse spectrum of information systems, ranging  \n",
            "from  stock price quotation systems, to track records databases, to real -time file systems.  What \n",
            "distinguish these databases from non  real-time databases is the perishable nature of the data \n",
            "maintained by them.  Specifically, a real -time database contains data o bjects, called image objects  \n",
            "that represent real -world objects. The attributes of an image object are those of the represented \n",
            "real world object.  \n",
            "For example, an air traffic control database contains image objects that represent aircraft in the \n",
            "coverage a rea. The attributes of such an image object include the position and heading of the \n",
            "aircraft. The values of these attributes are updated periodically based on the measured values of \n",
            "the actual position and heading provided by the radar system. Without this  update, the stored \n",
            "position and heading will deviate more and more from the actual position and heading. In this \n",
            "sense, the quality of stored data degrades. This is why we say that real -time data are perishable. \n",
            "In contrast, an underlying assumption of no n real-time databases (e.g., a payroll database) is that \n",
            "in the absence of updates the data contained in them remain good (i.e., the database remains in \n",
            "some consistent state satisfying all the data integrity constraints of the database).  \n",
            " \n",
            "MULTIMEDIA APPLI CATIONS:  \n",
            " \n",
            "A multimedia application may process, store, transmit, and display any number of video streams, \n",
            "audio streams, images, graphics, and text. A video stream is a sequence of data frames which \n",
            "encodes a video. An audio stream encodes a voice, sound, or music. Without compression, the \n",
            "storage space and transmission bandwidth required by a video are enormous. (As an example, we \n",
            "consider a small 100 × 100 -pixel, 30 -frames/second color video. The intensity and color of each \n",
            "pixel is given by the sample va lues of a luminance and two chrominance signal components,12 \n",
            "respectively, at the location of the pixel. If uncompressed, the video requires a transmission \n",
            "bandwidth of 2.7 Mbits per second when the value of each component at each pixel is encoded \n",
            "with 3 b its.) Therefore, a video stream, as well as the associated audio stream, is invariably \n",
            "compressed as soon as it is captured.\n",
            "12 \n",
            " \n",
            "RTS \n",
            " Chapter2  \n",
            "JOBS AND PROCESSORS:  \n",
            " \n",
            "Each  unit of work that is scheduled and executed by the system  is called a job and a set of related \n",
            "jobs which  jointly provide some system function a task. Hence, the computation of a control law \n",
            "is a job.  So is the computation of a FFT (Fast Fourier Transform) of sensor data, or the \n",
            "transmission  of a data packet, or the retrieval of a file, and so on.  \n",
            "A job executes or is executed by the (operating) system. Every job  executes on some resource. \n",
            "For example, the jobs mentioned above execute on a CPU, a network,  and a disk, respectively. \n",
            "These resources are called servers in queuing theory literatu re and, sometimes, active resources \n",
            "in real -time systems literature. To avoid overloading this term, we call  all these resources \n",
            "processors except occasionally when we want to be specific about what  they are.  \n",
            " \n",
            "RELEASE TIMES, DEADLINES, AND TIMING CONSTRAIN TS \n",
            " \n",
            "The release time  of a job is the instant of time at which the job becomes available for  execution. \n",
            "The job can be scheduled and executed at any time at or after its release time  whenever its data \n",
            "and control dependency conditions are met.  \n",
            " \n",
            "As an example, we consider a  system which monitors and controls several furnaces. After it is \n",
            "initialized and starts execution  (say at time 0), the system samples and reads each temperature \n",
            "sensor every 100 msec and  places the sampled readings in memory. It also  computes the control \n",
            "law of each furnace  every 100 msec in order to process the temperature readings and determine \n",
            "flow rates of fuel,  air, and coolant. Suppose that the system begins the first control -law \n",
            "computation at time 20  msec. The fact that the co ntrol law is computed periodically can be stated \n",
            "in terms of release  times of the control -law computation jobs J0, J1, . . . , Jk, . . . . The release \n",
            "time of the job Jk in this job stream is 20 + k × 100 msec, for k = 0, 1, . . . .  We say that jobs have\n",
            "13 \n",
            " \n",
            "RTS \n",
            " no release time if all the jobs are released when the system begins execution . So release times are \n",
            "20 ms , 120 ms ,220 ms…………………….  \n",
            " \n",
            " \n",
            "The deadline  of a job is the instant of time by which its execution is required to be  completed. \n",
            "Suppose that in the previous example, each control -law computation job must  complete by the \n",
            "release time of the subsequent job. Then, their deadlines are 120 msec, 220  msec, and so on, \n",
            "respectively. Alternatively, if the control -law computation jobs must complete  sooner, thei r \n",
            "deadlines may be 70 msec, 170 msec, and so on. We say that a job has no  deadline if its deadline \n",
            "is at infinity.  \n",
            " \n",
            " \n",
            "OTHER DEFINITIONS:  \n",
            " \n",
            "RESPONSE TIME: the length of time from the release time of the job to the instant when it \n",
            "completes.  \n",
            "Response time = J ob completion time – Job release time  \n",
            "Job’s timing requirements can be expressed in terms of “response time .\n",
            "14 \n",
            " \n",
            "RTS \n",
            " RELATIVE DEADLINE:  the maximum allowable response time of a job its relative deadline . \n",
            "The relative deadline of above figure is 100.  \n",
            "ABSOLUTE DEADLINE : is release time plus relative deadline.  The absolute deadline of above \n",
            "figure is 120.  \n",
            " \n",
            "These terminologies can be illustrated as following figure  \n",
            " \n",
            "TIMING CONSTRAINT:  \n",
            " \n",
            "We call a constraint imposed on the timing behavior of a job a timing constraint . In its simplest \n",
            "form, a timing constraint of a job can be specified in terms of its release time and relative or \n",
            "absolute deadlines, as illustrated by the above example. Some complex timing constraints cannot \n",
            "be specified conveniently in terms of release times and deadline . \n",
            " \n",
            "HARD AND SOFT TIMING CONSTRAINTS : \n",
            " \n",
            "They  are based on the functional criticality of jobs, usefulness of late results, and deterministic or  \n",
            "Probabilistic nature of the constraints.  \n",
            "A timing constraint or deadline is hard if the failure to meet it is considered to be a fatal fault. A \n",
            "hard deadline is imposed on a job because a late result produced by the job after the deadline \n",
            "may have disastrous consequences. (As examples, a late command to stop a train may cause a\n",
            "15 \n",
            " \n",
            "RTS \n",
            " collisi on, and a bomb dropped too late may hit a civilian population instead of the intended \n",
            "military target.)  \n",
            " In contrast, the late completion of a job that has a soft deadline is undesirable. However, a few \n",
            "misses of soft deadlines do no serious harm; only the  system‟s overall performance becomes \n",
            "poorer and poorer when more and more jobs with soft deadlines complete late.  \n",
            "In real -time systems literature, the distinction between hard and soft timing constraints  is \n",
            "sometimes stated quantitatively in terms of the usefulness of results (and therefore the overall  \n",
            "system performance) as functions of the tardinesses of jobs. The tardiness of a job measures  how \n",
            "late it completes respective to its deadline. Its tardiness is zero if the job completes  at or before \n",
            "its dead line; otherwise, if the job is late, its tardiness is equal to the difference  between its \n",
            "completion time (i.e., the time instant at which it completes execution) and its  deadline. The \n",
            "usefulness of a result produced by a soft real -time job (i.e, a job wit h a soft  deadline) decreases \n",
            "gradually as the tardiness of the job increases, but the usefulness of a result  produced by a hard \n",
            "real-time job (i.e., a job with a hard deadline) falls off abruptly and  may even become negative \n",
            "when the tardiness of the job b ecomes larger than zero. The deadline  of a job is softer if the \n",
            "usefulness of its result decreases at a slower rate. By this means, we  can define a spectrum of \n",
            "hard/soft timing constraints.   \n",
            "Sometimes, we see this distinction made on the basis of whether t he timing constraint  is \n",
            "expressed in deterministic or probabilistic terms. If a job must never miss its deadline, then  the \n",
            "deadline is hard. On the other hand, if its deadline can be missed occasionally with some  \n",
            "acceptably low probability, then its timing  constraint is soft . \n",
            " \n",
            "HARD TIMING CONSTRAINTS AND TEMPORAL QUALITY -OF-SERVICE GUARANTEES:  \n",
            " \n",
            "The timing constraint of a job  is hard, and the job is a hard real -time job, if the user requires the \n",
            "validation that the system  always meets the timing constraint. By validation , we mean a \n",
            "demonstration by a provably  correct, efficient procedure or by exh austive simulation and \n",
            "testing. . \n",
            "On the other hand, if no validation is required, or only a demonstration that the job  meets some  \n",
            "statistical constraint (i.e., a timing constraint specified in terms of statistical averages)  suffices, \n",
            "then the timing constraint of the job is soft.\n",
            "16 \n",
            " \n",
            "RTS \n",
            " This way to differentiate between hard and soft timing constraints is compatible with the  \n",
            "distinction be tween guaranteed and best-effort services  \n",
            "If the user wants the temporal quality (e.g., response time and jitter) of the service provided by  a \n",
            "task guaranteed and the satisfaction of the timing constraints defining the temporal quality  \n",
            "validated, then the timing constraints are hard. On the other hand, if the user demands the best  \n",
            "quality of service the system can provide but allows the system to deliver qualities below what  \n",
            "is defined by the timing constraints, then the timing constraints are soft.   \n",
            " \n",
            "SOME REASONS FOR REQUIRING TIMING GUARANTEES  \n",
            "Many embedded systems are hard real -time systems. Deadline s of jobs in an embedded system \n",
            "are typically derived from the required responsiveness of the sensors and actuators monitored \n",
            "and controlled by it. As an example, we consider an automatically controlled train. It cannot stop \n",
            "instantaneously. When the signal is red (stop), its bra king action must be activated a certain \n",
            "distance away from the signal post at which the train m ust sto p. This braking distance depends \n",
            "on the speed of the train and the safe value of decele ration. From the speed and safe deceleration \n",
            "of the train, the controller can compute the time for the train to travel the braking distance. This \n",
            "time in turn imposes a constraint on the response time of the jobs which sense  and process the \n",
            "stop signal and activate the brake. No one would question that this timing constraint should be \n",
            "hard and that its satisfaction must be guaranteed.  \n",
            "Similarly, each control -law computati on job of a flight controller must be completed in time so \n",
            "that its command can be issued in time. Otherwise,  the plane controlled by it may become \n",
            "oscillatory (and the ride bumpy) or even unstable and u ncontrollable. For this reason, we want \n",
            "the timely co mpletion of all control -law computations guaranteed.  \n",
            " \n",
            "HARD REAL -TIME SYSTEMS:  \n",
            "A hard real -time task is one that is constrained to produce its results within certain predefined \n",
            "time bounds. The system is considered to have failed whenever any of its  hard re al-time tasks \n",
            "does not produce its required results before the specified time bound. An example of a system \n",
            "having hard real -time tasks is a robot. The robot cyclically carries out a number of activities \n",
            "including communication with  the host system, loggin g all completed activities, sensing the \n",
            "environment to detect any obstacles present, tracking the objects of interest, path planning,\n",
            "17 \n",
            " \n",
            "RTS \n",
            " effecting next move, etc. Now consider that the robot suddenly encounters an obstacle. The robot \n",
            "must detect it and as soo n as possible try to escape colliding with it. If it fails to respond to  it \n",
            "quickly (i.e. the concerned tasks are not completed before the required time bound) then it would \n",
            "collide with the obstacle and the robot would be considered to h ave failed. Theref ore detecting \n",
            "obstacles and reacting to it are hard real -time tasks.  Another application having hard real -time \n",
            "tasks is an anti -missile system. An anti -missile system consists of the following critical activities  \n",
            "(tasks). An anti -missile system must first detect all incoming missiles, properly position the anti -\n",
            "missile gun, and then fire to destroy the incoming missile before the incoming missile can do any \n",
            "damage. All these tasks are hard real - time in nature and the anti -missile system would be  \n",
            "considered to have failed, if any of its tasks fails to complete before the corresponding deadlines.  \n",
            " \n",
            "SOFT REAL TIME SYSTEMS:  \n",
            "A system in which jobs have soft deadlines is a soft real -time system . Soft real -time tasks also  \n",
            "have time bounds associated with  them. However, unlike hard real-time tasks, the timing \n",
            "constraints on soft real -time tasks are not expressed as absolute values. Instead, the constraints \n",
            "are expressed either in terms of the average response times required . Examples of such systems \n",
            "include on -line transaction systems and telephone switches, as well as electronic games , \n",
            "multimedia system,  web browsing. Normally, after an URL (Uniform Resource Locater) is \n",
            "clicked, the corresponding web page is fetched and displayed within a couple of seconds on the \n",
            "average. However, when it takes several minutes to display a requested page, we still do not \n",
            "consider the system  to have failed, but merely express that the performance of the system has \n",
            "degraded. Another example of a soft real -time task is a task handling a request for a seat \n",
            "reservation in a railway reservation application. Once a request for re servation is made, the \n",
            "response should occur within 20 seconds on the average. The response may either be in the form \n",
            "of a printed ticket or an apology message on account  of unavailability of  seats. Alternatively, we \n",
            "might state the constraint on the ticke ting task as: At least in case of 95% of reservation requests, \n",
            "the ticket should be processed and printed in less than 20 seconds. Let us now analyze the impact \n",
            "of the failure of a soft real -time task to meet its deadline, by taking the example of the rail way \n",
            "reservation task. If the ticket is printed in about 20 seconds, we feel that the system is working \n",
            "fine and get a feel of having obtained instant results. As already stated, missed deadlines of soft \n",
            "real-time tasks do not result i n system failure\n",
            "18 \n",
            " \n",
            "RTS \n",
            " Chapt er-3 \n",
            "Reference model for real -time systems   \n",
            "Reference model is characterized by:  \n",
            " A model that describes applications running on the system.  \n",
            " A model that describes the resources available to those applications.  \n",
            " A scheduling algorithm that define how the app lications execute and use the resources.  \n",
            " \n",
            "Processors and resources  \n",
            "We divide all the system resources into two types:  \n",
            " processors (sometimes called servers or active resources such as computers, data links, database servers \n",
            "etc.) \n",
            " other  passive resources (such as memory, sequence numbers, mutual exclusion locks etc.)  \n",
            "Jobs may need some resources in addition to the processor in order to make progress.  \n",
            " \n",
            "Processors  \n",
            " Processors carry out machine instructions, move data, retrieve files, process queries etc.  \n",
            " Every job must have one or more processors in order to make progress towards \n",
            "completion.  \n",
            " Sometimes we need to distinguish types of processors.  \n",
            " \n",
            "Types of processors  \n",
            "• Two processors are of the same type if they can be used interchangeably  and are \n",
            "functionally identical.  \n",
            "– Two data links with the same transmission rates between the same two nodes are \n",
            "considered processors of the same type.  Similarly processors in a symmetric \n",
            "multiprocessor system are of the same type.  \n",
            "• One of the attributes o f a processor is its speed.  We will assume that the rate of progress \n",
            "a job makes depends on the speed of the processor on which it is running.  \n",
            " \n",
            " \n",
            "Speed\n",
            "19 \n",
            " \n",
            "RTS \n",
            " We can explicitly model the dependency of job progression and processor speed by making the \n",
            "amount of ti me a job requires completing a function of the processor speed. In contrast we do not \n",
            "associate speed with a resource. How long a job takes to complete does not depend on the speed \n",
            "of any resource it uses during execution.  \n",
            "Examples of processors:  \n",
            "Threads scheduled on CPU, data scheduled on a transmission link, read/write req uests scheduled \n",
            "to disks, transmission scheduled on database server.  \n",
            "Resources:  \n",
            "A resource R is a passive entity upon which jobs may depend. Resources are of different types \n",
            "and sizes but they do not have a speed attribute. Example includes memory, database locks, \n",
            "mutexes etc.  Some Resources are generally reusable and they are not con sumed during use whereas other \n",
            "resources are consumed during use and cannot be used again.  Some resources are serially \n",
            "reusable. There may be many units of a serial resource, but each can only be used by one job at a \n",
            "time.  \n",
            "A resource is plentiful if no job  is ever prevented from running by the lack of this resource.  \n",
            " \n",
            "Processor or Resource?  \n",
            " \n",
            "• We sometimes model some elements of the system as processors and sometimes as \n",
            "resources, depending on how we use the model.  \n",
            "• For example, in a distributed system a comput ation job may invoke a server on a remote \n",
            "processor.  \n",
            "– If we want to look at how the response time of this job is affected by the way the \n",
            "job is scheduled on its local processor, we can model the remote server as a \n",
            "resource.  \n",
            "– We may also model the remote serv er as a processor.  \n",
            "• There are no fixed rules to guide us in deciding whether to model something as a \n",
            "processor or as a resource, or to guide us in many other modelling choices.  \n",
            "• A good model can give us better insight into the real -time problem we are consid ering.  \n",
            "• A bad model can confuse us and lead to a poor design and implementation.\n",
            "20 \n",
            " \n",
            "RTS \n",
            " • In many ways this is an art which requires some skill but provides great freedom for \n",
            "designing and implementing real -time systems.  \n",
            " \n",
            "Real -time workload parameters  \n",
            " The number of tasks or jobs in the system.  \n",
            "– In many embedded systems the number of tasks is fixed for each operational \n",
            "mode, and these numbers are known in advance.  \n",
            "– In some other systems the number of tasks may change as the system executes.  \n",
            "– Nevertheless, the number of tasks with hard timing constraints is known at all \n",
            "times.  \n",
            "– When the satisfaction of timing constraints is to be guaranteed, the admission and \n",
            "deletion of hard real -time tasks is usually done under the control of the run -time \n",
            "system.  \n",
            " The run -time system  \n",
            "• The run-time system must maintain information on all existing hard real -time tasks, \n",
            "including the number of such tasks, and all their real -time constraints and resource \n",
            "requirements.  \n",
            "The job  \n",
            "• Each job Ji is characterized by its temporal parameters, interconnect ion parameters and \n",
            "functional parameters.  \n",
            "• Its temporal parameters tell us its timing constraints and behaviour.  \n",
            "• Its interconnection parameters tell us how it depends on other jobs and how other jobs \n",
            "depend on it.  \n",
            "• Its functional parameters specify the intri nsic properties of the job.  \n",
            " \n",
            "Job temporal parameters  \n",
            "• For job Ji  \n",
            "– Release time  ri  \n",
            "– Absolute deadline  di  \n",
            "– Relative deadline  Di  \n",
            "– Feasible interval  (ri, di]\n",
            "21 \n",
            " \n",
            "RTS \n",
            " • di and Di are usually derived from the timing requirements of Ji, other jobs in the same \n",
            "task as Ji, and the overall system.  \n",
            "• These parameters are part of the system specification.  \n",
            " \n",
            "Release time:  \n",
            "• In many systems we do not know exactly when each job will be released.  i.e. we do not \n",
            "know ri . But  We know that ri is in the range [ ri-, ri+] \n",
            "– Ri can be as early  as ri- and as late as ri+  \n",
            "– Some models assume that only the range of ri is known and call this range, \n",
            "release time jitter.  \n",
            "– If the release time jitter is very small compared with other temporal parameters, \n",
            "we can approximate the actual release time by its earliest ri- or latest ri+ release \n",
            "time, and say that the job has a fixed release time.  \n",
            " \n",
            "Sporadic jobs  \n",
            "Most real -time system s have to respond to external events which occur randomly. When such an \n",
            "event occurs the system executes a set of jobs in response.  The release times of those jobs are not \n",
            "known until the event triggering them occurs. These jobs are called sporadic jobs  or aperiodic \n",
            "jobs because they are released at random times.  \n",
            " \n",
            "Release time of sporadic job  \n",
            "• The release times of sporadic and aperiodic jobs are random variables.  \n",
            "• The system model gives the probability distribution A( x) of the release time of such a job.  \n",
            "• A(x) gives us the probability that the release time of a job is at or earlier than x, or in the \n",
            "case of interrelease time, that it is less than or equal to x. \n",
            " \n",
            "Arrival time:  \n",
            "Rather than speaking of release times for aperiodic jobs, we sometimes use the term a rrival time \n",
            "(or interarrival time) which is commonly used in queueing theory.An aperiodic job arrives when \n",
            "it is released.  A(x) is the arrival time distribution or interarrival time distribution.\n",
            "22 \n",
            " \n",
            "RTS \n",
            " Execution Time:  \n",
            "Another temporal parameter of a job Ji is its execution time, ei. ei is the time required to complete \n",
            "the execution of Ji when it executes alone and has all the resources it requires.  The value of ei \n",
            "depends mainly on the complexity of the job and the speed of the processor used to execute the \n",
            "job. ei does not depend on how the job is scheduled.  \n",
            "The execution time of a job may vary for many reasons.  \n",
            "– A computation may contain conditional branches and these conditional branches \n",
            "may take different amounts of time to complete.  \n",
            "– The branches taken during the execution of a job depend on input data.  \n",
            "– If the underlying system has performance enhancing features such as caches and \n",
            "pipelines, the execution time can vary each time a job executes, even without \n",
            "conditional branches.  \n",
            "Thus the actual execution time o f a computational job may be unknown until it completes.  \n",
            " \n",
            "Characterizing execution time  \n",
            "• What can be determined through analysis and measurement are the maximum and \n",
            "minimum amounts of time required to complete each job.  \n",
            "• We know that the execution time ei of job Ji is in the range [ ei-, ei+] where ei- is the \n",
            "minimum execution time and ei+ is the maximum execution time of job Ji. \n",
            "• We assume that we know ei- and ei+ of every hard real -time job  Ji, even if we don‟t know \n",
            "ei. \n",
            " \n",
            "Maximum execution time  \n",
            "• For the purpose  of determining whether each job can always complete by its deadline, it \n",
            "suffices to know its maximum execution time.  \n",
            "• In most deterministic models used to characterize hard real -time applications, the term \n",
            "execution time ei of each job Ji specifically means its maximum execution time.  \n",
            "• However we don‟t mean that the actual execution time is fixed and known, only that it \n",
            "never exceeds our ei (which may actually be  ei+) \n",
            " \n",
            "Periodic task model:\n",
            "23 \n",
            " \n",
            "RTS \n",
            " It is a deterministic model . \n",
            "The jobs of a given task are repeated at regular and are modeled as periodic, with period p. \n",
            "Accuracy of model decreases with increasing jitter. Task T i is a series of periodic Jobs J ij which \n",
            "may be described with the following parameters:  \n",
            "pi - period , minimum inter -release interval b etween jobs in Task T i.  \n",
            "ei - maximum execution time for jobs in task T i. \n",
            "rij - release time of the jth Job in Task i (J ij in T i). \n",
            "i - phase of Task T i, equal to r i1, i.e. it is the release time of the first job in the task T i. \n",
            "H - Hyperperiod  = Least Common Multiple of p i for all i: H = lcm(pi), for all i. The number of \n",
            "jobs in a hyperperiod is equal to the sum of (H/p i) over all i.  \n",
            "ui - utilization of Task T i and is equal to e i/pi. \n",
            "U - Total utilization = Sum over all u i. \n",
            "di - absolute deadli ne \n",
            "Di - relative deadline  \n",
            "(ri, di] - feasible interval  \n",
            "In other words the periodic task model is a four tuples ( i, pi, ei, Di ). E.g consider following \n",
            "periodic task  \n",
            " \n",
            "  \n",
            "The number of jobs in the hyper period = sum (H/p1 +H/p2)  \n",
            "            =sum (15/3+15/5)  \n",
            "        = 8 \n",
            "       Total utilization= sum (e1/p1 +e2/p2)\n",
            "24 \n",
            " \n",
            "RTS \n",
            " =sum(1/3+2/5)  \n",
            "=0.733  \n",
            "Functional parameters  \n",
            "• While scheduling and resource control decisions are made independently of most \n",
            "functional characteristics of jobs, there are several  functional properties that do affect \n",
            "these decisions.  \n",
            "• The workload model must explicitly describe these properties using functional \n",
            "parameters:  \n",
            "– Preemptivity  \n",
            "– Criticality  \n",
            "– Optional interval  \n",
            "– Laxity type  \n",
            "Preemptivity of Jobs:  \n",
            "  The scheduler may suspend the execution of a less urgent job and give the processor to a more \n",
            "urgent job.  Later, the less urgent job can resume its execution. This interruption of job execution \n",
            "is called preemption.  A job is preemptable  if its execution  can be suspended at any time to allow \n",
            "the execution of other jobs and can later be resumed from the point of suspension.  A job is non-\n",
            "preemptable  if it must be executed from start to completion without interruption.  This constraint \n",
            "may be imposed because its execution, if suspended, must be executed again from the beginning. \n",
            "An example is an interrupt handling job.  An interrupt handling job usually begins by saving the \n",
            "state of the processor.  This small portion of the job is non -preemptable since suspend ing the \n",
            "execution may cause serious errors in the data structures shared by the jobs.  \n",
            "e.g. in the case of CPU jobs, the state of the pre -empted job includes the contents of the CPU \n",
            "registers.  After saving the contents of the registers in memory and befor e the preempting job can \n",
            "start, the operating system must load the new register values, clear pipelines, perhaps clear the \n",
            "caches, etc.  These actions are called a context switch . The amount of time required to accomplish \n",
            "a context switch is called a contex t-switch time.  \n",
            "The terms context switch and context -switch time are used to mean the overhead work done \n",
            "during preemption, and the time re quired to accomplish this work.  \n",
            "Criticality of Jobs\n",
            "25 \n",
            " \n",
            "RTS \n",
            " In any system, jobs are not equally important.  The importance (or criticality) of a job is a \n",
            "positive number that indicates how critical a job is with respect to other jobs.  The more \n",
            "important a job, the higher its priority or the larger its weight  Because priority and weight can \n",
            "have other meanings, During an overload w hen it is not possible to schedule all the jobs to meet \n",
            "their deadlines, it may make sense to sacrifice the less critical jobs, so that the more critical jobs \n",
            "meet their deadlines.  For this reason, some scheduling algorithms try to optimize weighted \n",
            "perfor mance measures, taking into account the importance of jobs.  \n",
            " \n",
            "Optional Executions  –  \n",
            "An application may be structured in such a way that some portions are optio nal while the rest is \n",
            "mandatory. Delay in completion or skipping of an optional job may degrade p erformance but \n",
            "still the sy stem functions are satisfactory. Mandatory jobs m ust be executed to completion. \n",
            "During transient overload, the mandatory portions must run to completion while the  optional \n",
            "portion may be skipped , completely or partially executed.  \n",
            " \n",
            "Laxity type or laxity function – \n",
            " Laxity can be used to indicate the relative importance of a time constraint, for example hard \n",
            "versus soft constraints. May be supplemented with a utility function (for soft constraints) that \n",
            "gives the usefulness of a result versus its degree of tardiness.  The following figure  gives several \n",
            "usefulness functions as examples. The ones shown as solid step  functions are usually associated \n",
            "with hard real -time jobs. The u sefulness of the result becomes zero or negative as soo n as the job \n",
            "is tardy.  The dashe d and dotted lines in following figure  show two other usefu lness functions. In \n",
            "particular, the dotted ones may be that of a point -of-sales transaction,  for example, one that \n",
            "executes to check whether you have enough credit for the current purchase. If the job  is late, you \n",
            "and the salesperson become more and more impatient. The use fulness of the result decreases \n",
            "gradually. It may be tolerable if the update completes slightly late and the price x written into the \n",
            "database is s omewhat old. However, if the tra nsaction completes so late that the current price \n",
            "differs significantly from x, the result x can b e misleading. By that time, the usefulness o f this \n",
            "update becomes negative.\n",
            "26 \n",
            " \n",
            "RTS \n",
            "  \n",
            " Fig:- Examples of usefulness function  \n",
            " \n",
            "Resource  parameters of jobs and parameters of resources:  \n",
            "Every job requires a processor throughout its execution.  A job may also require some resources.  \n",
            "The resource parameters of each job give us the type of processor and the units of each resource \n",
            "type required by the job and the time intervals during its execution when the resources are \n",
            "required.   \n",
            "Preemptivity of Resources: A resource parameter is preemptivity . A resource is non-\n",
            "preemptable  if each unit of the resource is constrained to be used serially.  Once a unit of a non -\n",
            "preemptable resource is allocated to a job, other jobs needing the unit must wait until the job completes its use.  If \n",
            "jobs can use every unit of a resource in an interleaved way, the resource is preemptable.  A lock \n",
            "on a data object is an exam ple of a non -preemptable resource . \n",
            "This does not mean that the job is non -preemptable on other resources or on the processor.  \n",
            "The transaction can be preempted on the processor by other transactions not waiting for the \n",
            "locks.  \n",
            "ii.  Resource Graph:  \n",
            "• A resource  graph describes the configuration of resources.  \n",
            "• There is a vertex Ri for every processor or resource Ri in the system.  \n",
            "• We can treat resources and processors similarly for the sake of convenience.  \n",
            "• The attributes of the vertex are the parameters of the resource.\n",
            "27 \n",
            " \n",
            "RTS \n",
            " • The resource type  of a resource tells us whether the resource is a processor or a passive \n",
            "resource, and its number  gives us the number of available units.  \n",
            "• Edges in resource graphs represent the relationship among resources.  \n",
            "• Using different types of edges we can describe different configurations of the underlying \n",
            "system.  \n",
            "• There are 2 types of edges in resource graphs  \n",
            "• An edge from vertex Ri to vertex Rk can mean that Rk is a component of Ri.   E.g. a \n",
            "memory is part of a computer and so is a monitor.  \n",
            "• This edge is an is-a-part-of edge . \n",
            "• The subgraph containing all the is -a-part-of edges is a forest.   The root of each tree \n",
            "represents a major component, with subcomponents represented by vertices.  E.g. the \n",
            "resource graph of a system containing 2 computers consists of 2 trees.  The root of each \n",
            "tree represents a computer with children of this vertex including CPUs etc.  \n",
            "• The other type of edge in resource graphs a re accessibility edges . \n",
            "• Some edges in resource graphs represent connectivity between components.  \n",
            "• These edges are called accessibility edges . \n",
            "• e.g. if there is a connection between two CPUs in the two computers, then each CPU is \n",
            "accessible from the other computer and there is an accessibility edge from each computer \n",
            "to the CPU of the other computer.  \n",
            "• Each accessibility edge may have several parameters.  A parameter of an accessibility \n",
            "edge from a processor Pi to another Pk is the cost of sending a unit of data from a job \n",
            "executing on Pi to a job executing on Pk  \n",
            "• Some algorithms use such information to deci de how to allocate jobs and resources to \n",
            "processors in a statically configured system.  \n",
            "Precedence constraints:  \n",
            "Data and control dependencies among jobs may constrain the order in which they can execute \n",
            "Such jobs are said to have precedence constraints . If jobs can execute in any order, they are said \n",
            "to be  independent.  \n",
            "Example: Consider an information server.  Before a query is processed and the requested information \n",
            "retrieved, its authorization to access the information must first be checked. The retrieval job\n",
            "28 \n",
            " \n",
            "RTS \n",
            " cannot begin execution before the authentication job completes. The communication job that \n",
            "forwards th e information to the requester cannot begin unt il the retrieval job completes.  \n",
            " \n",
            "Precedence Graph and Task graph:  \n",
            "We use a partial order relation <, called a precedence relation, over the set of jobs to specify the \n",
            "precedence constraints among jobs.  \n",
            "A job J i is a predecessor of another job j k (and j k is a successor of j i) if j k cannot begin execution \n",
            "until the execution of j i completes.  This is represented as j i < jk \n",
            "• Ji is an immediate predecessor of j k \n",
            "(and j k is is an immediate successor of j i) \n",
            "if ji < jk and there is no other job j j such that j i < jj < jk  \n",
            "• Two jobs j i and j k are independent when neither j i < jk nor j k < ji  \n",
            "• A job with predecessors is ready  for execution when the time is at or after its release time \n",
            "and all of its predecessors are  completed.  \n",
            " \n",
            "A precedence graph  is a directed graph which represents the precedence constraints \n",
            "among a set of jobs J.  Each vertex represents a job in J. There is a directed edge from \n",
            "vertex Ji to vertex Jk when the job Ji is an immediate predecessor of job Jk  \n",
            " \n",
            "Task graph:  \n",
            "• A task graph, which gives us a general way to describe an application system, is an \n",
            "extended precedence graph.  \n",
            "• As in a precedence graph, vertices represent jobs.  They are shown as circles and squares \n",
            "(the distinction between them will come later).  \n",
            "• The numbers in the bracket above each job gives us its feasible interval.  \n",
            "• The edges in the graph represent dependencies among jobs.  \n",
            "• If all the edges are precedence edges representing precedence constraints th en the graph \n",
            "is a precedence graph.  \n",
            "Example of task graph :\n",
            "29 \n",
            " \n",
            "RTS \n",
            "  \n",
            " \n",
            "The system shown in the sample task graph includes two periodic tasks.   \n",
            "Job row 1: Periodic task phase = 0, period = 2, relative deadline = 7 Independent jobs .   \n",
            "Job row 2: Periodic task phase = 2, period = 3, relative deadline = 3 Depende nt jobs, precedence \n",
            "constraints.  Hence the jobs must be executed in serial order.   \n",
            "Why Task Graph?  \n",
            "A task graph like the example is only really necessary when the system contains components \n",
            "which have complex d ependencies like the subgraph below the periodic tasks.  \n",
            "Many types of interactions and communication among jobs are not captured by a precedence \n",
            "graph but can be captured by a task graph.  \n",
            "Unlike a precedence graph, a task graph can contain difference types  of edges representing \n",
            "different types of dependencies.  \n",
            " \n",
            "Data Dependency:  \n",
            "Data dependency cannot be captured by a precedence graph.  In many real -time systems jobs \n",
            "communicate via shared data.  Often the designer chooses not to synchronize producer and \n",
            "consumer jobs.  Instead the producer places the data in a shared address space to be used by the\n",
            "30 \n",
            " \n",
            "RTS \n",
            " consumer at any time.  In this case the precedence graph will show the producer and consumer jobs \n",
            "as independent since they are apparently not constrained to run in turn.  \n",
            "• In a task graph, data dependencies are represented explicitly by data dependency edges \n",
            "among jobs.  \n",
            "• There is a data dependency edge from the vertex Ji to vertex Jk in the task graph if the job \n",
            "Jk consumes data generated by Ji or the job Ji sends messages to Jk  \n",
            "• A parameter of an edge from Ji to Jk is the volume of data from Ji to Jk. \n",
            "• In multiple processor systems the volume of data to be transferred can be used to m ake \n",
            "decisions about scheduling of jobs on processors.  \n",
            " \n",
            "Other types of dependencies  \n",
            "The other dependencies are as follows.  \n",
            "1. Temporal dependency  \n",
            "2. AND/OR precedence constraints  \n",
            "3. Conditional branches  \n",
            "4. Pipeline relationship.  \n",
            "1. Temporal dependency  \n",
            "Some jobs may be constrained to complete within a certain amount of time relative to one  \n",
            "another. We call the difference in the completion times of two jobs the temporal distance  \n",
            "between them. Jobs are said to have a temporal distance constraint if their temporal distance \n",
            "must be no more than some finite value. Jobs with temporal distance constraints may or may not \n",
            "have deadlines.  e.g. in a video frame lip synchronization delay is limited to 160 msec .  In a task \n",
            "graph, temporal distance constraints among jobs are represente d by temporal  dependency  edges. \n",
            "There is a temporal -dependency edge from a vertex Ji to a vertex Jk if the job Jk must be \n",
            "completed within a certain time after Ji completes.  \n",
            " \n",
            "2. AND/OR precedence constraints  \n",
            "If a job having more than one predecessor job needs that all the immediate predecessor must \n",
            "have been completed before its execution can begin, then such jobs are called AND jobs , having \n",
            "AND precedence constraint dependency among them . AND jobs are repre sented by hollow \n",
            "circle in Task Graph.\n",
            "31 \n",
            " \n",
            "RTS \n",
            "  \n",
            " \n",
            "A square node is represented by a label (x/y) to indicate that the job can begin execution if „x’ \n",
            "out of „ y’ predecessors complete execution. If job having more than one predecessor jobs can \n",
            "begin execution at or after its release time provided one or more of its predecessor have \n",
            "completed execution Jobs having such kind of dependency on its predecessor is called  an OR \n",
            "job and is represented by a square node . \n",
            " \n",
            " \n",
            "3. Conditional branches  \n",
            "Sub graph beginning with branch job and ending with join job is called conditional block . lk \n",
            "precedence graphs are needed to represent a system with k conditional block each having l branches .\n",
            "32 \n",
            " \n",
            "RTS \n",
            " 4. Pipeline relationship  \n",
            "Each consumer granule can begin execution when the previous granule of job and the \n",
            "correspondin g producer granule is completed. In the task graph a pipeline relationship among \n",
            "job is shown by pipeline edge ,  indicated by a dotted edge.                                      \n",
            "Scheduling hierarchy:  \n",
            " \n",
            "• The figure „model of a real -time system‟ shows the three elements of our model of real -\n",
            "time systems.  \n",
            "• The application system is represented by  \n",
            "– a task graph which gives  the processor time and resource requirements of jobs, \n",
            "their timing constraints and dependencies  \n",
            "– A resource graph describing the resources available to execute the application \n",
            "system, their attributes and rules governing their use\n",
            "33 \n",
            " \n",
            "RTS \n",
            " – And between these graphs are the scheduling and resource access -control \n",
            "algorithms used by the operating system.  \n",
            "Scheduler and Schedules:  \n",
            "• Jobs are scheduled and allocated resources according to a chosen set of scheduling algorithms \n",
            "and resource access -control protocols.  \n",
            "• The schedu ler is a module that implements these algorithms.  \n",
            "• The scheduler assigns processors to jobs, or equivalently, assigns jobs to processors.  \n",
            "• A schedule  is an assignment by the scheduler  of all the jobs in the system on the \n",
            "available processors.  \n",
            " \n",
            "A valid Schedule:  \n",
            "A valid schedule is the schedule satisfies the following conditions:  \n",
            "1.  Every processor is assigned to at most one job at any time.  \n",
            "2.  Every job is assigned at most one processor at any time.  \n",
            "3.  No job is scheduled before its release time.  \n",
            "4.  Depending on the scheduling algorithms used, the total amount of processor time assigned to \n",
            "every job is equal to its maximum or actual execution time.  \n",
            "5.  All the precedence and resource usage constraints are satisfied.  \n",
            " \n",
            "Feasibility:  \n",
            "• A valid schedule  is a feasible schedule  if every job completes by its deadline and in \n",
            "general meets its timing constraints.  \n",
            "• A set of jobs is schedulable  according to a scheduling algorithm if when using the \n",
            "algorithm the scheduler always produces a feasible schedule.  \n",
            " \n",
            "Optimality:  \n",
            "• A hard real -time scheduling algorithm is optimal  if using the algorithm the scheduler \n",
            "always produces a feasible schedule if the given set of jobs has feasible schedules.  \n",
            "• If an optimal algorithm cannot find a feasible schedule, we can conclude that a given set \n",
            "of jobs cannot feasibly be scheduled by any algorithm.\n",
            "34 \n",
            " \n",
            "RTS \n",
            " Performance measures  \n",
            "The following are the performance measure of real time system.  \n",
            "• Miss rate : percentage of jobs executed but completed late  \n",
            "• Loss rate : percentage of jobs discarded  \n",
            "• Invalid rate : sum of miss and loss rate. \n",
            "• Makespan : If all jobs have same release time and deadline then the completion time of \n",
            "last time is the makespan.  \n",
            "• Max or average response times  \n",
            "• Max or average tardiness/lateness  \n",
            "• Tardiness : Zero if completion time <= deadline, otherwise equals (completion time - \n",
            "deadline).  \n",
            "• Lateness : difference between completion time and deadline, can be negative if early.  \n",
            "• Or another words  \n",
            "• Lateness  (L): L = Completion time - deadline (L > 0 if deadline is not met)  \n",
            "• Tardiness  (E): E = max{ L, 0} ( E = 0 if deadline is met)\n",
            "35 \n",
            " \n",
            "RTS \n",
            " Chapter -4 \n",
            "Commonly Used Approaches to Real -Time Scheduling  \n",
            "Three commonly used approaches to real -time scheduling are  :  \n",
            "– Clock -driven  \n",
            "– Weighted round -robin  \n",
            "– Priority -driven  \n",
            "The weighted round -robin approach is mainly used for scheduling real -time traffic in high -speed \n",
            "switched networks.  It is not ideal for scheduling jobs on CPUs.  \n",
            " \n",
            "Clock -Driven Approach  \n",
            "• Clock -driven scheduling is often called time -driven scheduling.  \n",
            "• When scheduling is clock -driven , decisions are made at specific time instants on what \n",
            "jobs should execute when.  \n",
            "• Typically in a system using clock -driven scheduling, all the parameters of hard real -time \n",
            "jobs are fixed and known.  \n",
            "• A schedule of the jobs is computed off -line and is stored fo r use at run -time.  \n",
            "• The scheduler schedules the jobs according to this schedule at each scheduling decision \n",
            "time.  \n",
            "• Thus scheduling overhead at run -time is minimized.  \n",
            "• Scheduling decisions are usually made at regularly spaced time instants.  \n",
            "• One way to implemen t this is to use a hardware timer set to expire periodically which \n",
            "causes an interrupt which invokes the scheduler.  \n",
            "• When the system is initialized, the scheduler selects and schedules the jobs that will \n",
            "execute until the next scheduling decision time and t hen blocks itself waiting for the \n",
            "expiration of the timer.  \n",
            "• When the timer expires, the scheduler repeats these actions.\n",
            "36 \n",
            " \n",
            "RTS \n",
            " Round -Robin approach:  \n",
            "• The round -robin approach is commonly used for scheduling time -shared applications.  \n",
            "• When jobs are scheduled in a r ound -robin system, every job joins a first -in-first-out \n",
            "(FIFO) queue when it becomes ready for execution.  \n",
            "• The job at the head of the queue executes for at most one time slice.  \n",
            "• If the job does not complete by the end of the time slice, it is preempted and p laced at the \n",
            "end of the queue to wait for its next turn.  \n",
            "• When there are n ready jobs in the queue, each job gets one time slice in n, that is every \n",
            "round . \n",
            "• Because the length of the time slice is relatively short (typically tens of milliseconds) the \n",
            "executi on of each jobs begins almost immediately after it becomes ready.  \n",
            "• In essence, each job gets 1/ nth share of the processor when there are n jobs ready for \n",
            "execution.  \n",
            "• This is why the round -robin algorithm is also known as the processor -sharing algorithm.  \n",
            " \n",
            "Weighted Round -Robin Approach:  \n",
            "• The weighted round -robin algorithm  has been used for scheduling real -time traffic in \n",
            "high-speed switched networks.  \n",
            "• Rather than giving all the ready jobs equal shares of the processor, different jobs may be \n",
            "given different weight s. \n",
            "• A job with weight wt gets wt time slices every round.  \n",
            "• The length of the round equals the sum of the weights of all the ready jobs.  \n",
            "• By adjusting the weights of jobs we can speed up or slow down the progress of each job.  \n",
            "• By giving each job a fraction of the processor, a round -robin scheduler delays the \n",
            "completion of every job.  \n",
            "• If round -robin scheduling is used to schedule precedence constrained jobs, the response \n",
            "time of a chain of jobs can get very large.  \n",
            "• For this reason, the weighted round -robin approac h is unsuitable for scheduling such \n",
            "jobs.\n",
            "37 \n",
            " \n",
            "RTS \n",
            " • However if a successor job is able to consume incrementally what is produced by a \n",
            "predecessor job, such as with a Unix pipe, weighted round -robin scheduling may be a \n",
            "reasonable approach.  \n",
            " \n",
            "For example consider two s ets of jobs J1 = {J1, 1,  J1 , 2} and J2 = {J2, 1,  J2 , 2}  \n",
            "• The release times of all jobs are 0  \n",
            "• The execution times of all jobs are 1  \n",
            "• J1, 1  and J2, 1 execute on processor P1 \n",
            "• J1, 2  and J2, 2 execute on processor P2\n",
            "38 \n",
            " \n",
            "RTS \n",
            " • We can see in the figure „round -robin  scheduling‟ that both sets of jobs complete \n",
            "approximately at time 4 if the jobs are scheduled in a weighted round -robin manner.  \n",
            "• In contrast, we can see that if the jobs on each processor are scheduled one after the \n",
            "other, one of the chains can complete at  time 2 and the other at time 3.  \n",
            "• The weighted round -robin approach does not require a sorted priority queue, only a \n",
            "round -robin queue.  \n",
            "This is a distinct advantage for scheduling message transmissions in ultrahigh -speed \n",
            "networks since fast priority queues are very expensive  \n",
            "Priority - Driven Approach:  \n",
            "• The term priority -driven  algorithms refer to a class of scheduling algorithms that never \n",
            "leave any resource idle intentionally.  \n",
            "• With a priority -driven algorithm a resource idles only when no job requiring the r esource \n",
            "is ready for execution.  \n",
            "• Scheduling decisions are made when events such as releases and completions of jobs \n",
            "occur.  \n",
            "• Priority -driven algorithms are event -driven . \n",
            "• Other commonly used terms for this approach are greedy scheduling , list scheduling , and \n",
            "work -conserving scheduling . \n",
            "• A priority -driven algorithm is greedy because it tries to make locally optimal decisions.  \n",
            "• Leaving a resource idle while some job is ready to use the resource is not locally optimal.  \n",
            "• When a processor or resource is available and some job can use it to make progress, a \n",
            "priority -driven algorithm never makes the job wait.  \n",
            "• However there are cases where it is better to have some jobs wait even when they are \n",
            "ready to execute and the resources they require are available.  \n",
            "• The term list sc heduling is also used because any priority -driven algorithm can be \n",
            "implemented by assigning priorities to jobs.  \n",
            "• Jobs ready for execution are placed in one or more queues ordered by the priorities of the \n",
            "jobs.  \n",
            "• At any scheduling decision time, the jobs with the highest priorities are scheduled and \n",
            "executed on the available processors.\n",
            "39 \n",
            " \n",
            "RTS \n",
            " • Hence a priority -driven scheduling algorithm is defined largely by the list of priorities it \n",
            "assigns to jobs.  \n",
            "• The priority list and other rules such as whether preemption is all owed, define the \n",
            "scheduling algorithm completely.  \n",
            "• Most non real -time scheduling algorithms are priority -driven.  \n",
            "Examples include:  \n",
            "• FIFO (first -in-first-out) and LIFO (last -in-first-out) algorithms which assign priorities to \n",
            "jobs based on their release times.  \n",
            "• SETF (shortest -execution -time-first) and LETF (longest -execution -time-first) algorithms \n",
            "which assign priorities based on job execution times.  \n",
            "• Because we can dynamically change the priorities of jobs, even round -robin scheduling \n",
            "can be thought of as priority -driven.  \n",
            "• The priority of the executing job is lowered to the minimum among all jobs waiting for \n",
            "execution after the job has executed for a time slice.  \n",
            "The following figure shows “examples of priority driven scheduling”  \n",
            "• The task graph is a precedenc e graph with all edges showing precedence constraints.  \n",
            "• The number next to the name of each job is its execution time.  \n",
            "• J5 is released at time 4.  \n",
            "• All the other jobs are released at time 0.  \n",
            "• We want to schedule and execute the jobs on two processors P1 and P2. \n",
            "• The schedulers of the processors share a common priority queue of ready jobs.  \n",
            "• Scheduling decisions are made whenever some job becomes ready for execution or some \n",
            "job completes.  \n",
            "The first schedule (a)  and (b)  shows the schedule of jobs on the two processors generated by \n",
            "the priority -driven algorithm following this priority assignment.  \n",
            "• At time 0, jobs J1, J2, and J7 are ready for execution.  \n",
            "• They are the only jobs in the priority queue at this time.\n",
            "40 \n",
            " \n",
            "RTS \n",
            " • Since J1 and J2 have higher priorities than J7 they are ahead of J7 in the queue and hence \n",
            "are scheduled.  \n",
            "• At time 1, J2 completes and hence J3 becomes ready. J3 is placed in the priority queue \n",
            "ahead of J7 and is scheduled on P2, the processor freed by J2. \n",
            "• At time 3 , both J1 and J3 complete. J5 is still not released. J4 and J7 are scheduled.  \n",
            "• At time 4, J5 is released.  Now there are three ready jobs. J7 has the lowest priority \n",
            "among them so it is preempted and J4 and J5 have the processors.  \n",
            "• At time 5, J4 completes. J7 resumes on processor P1. \n",
            "• At time 6, J5 completes.  Because J7 is not yet completed, both J6 and J8 are not yet ready \n",
            "for execution.  Thus processor P2 becomes idle.  \n",
            "• J7 finally completes at time 8.  J6 and J8 can now be scheduled on the processors.  \n",
            " \n",
            " \n",
            " \n",
            "Fig without preemption  \n",
            "The figure “examples of priority driven scheduling  \n",
            "Fig. With preemption\n",
            "41 \n",
            " \n",
            "RTS \n",
            "  \n",
            "Dynamic vs. Static system:  \n",
            "• We have seen examples of jobs that are ready for execution being placed in a priority \n",
            "queue common to all processors.  \n",
            "• When a processor is available, the job at the head of the queue executes on the processor, \n",
            "such a system is called a dynamic system , because jobs are dynamically dispatched  to \n",
            "processors.  \n",
            "• In the example of priority scheduling we allowed each pr eempted job to resume on any \n",
            "processor.  \n",
            "We say a job migrates  if it starts execution on a processor, is preempted, and later resumes on a \n",
            "different processor.  \n",
            "• An alternate approach to scheduling in multiprocessor and distributed systems is to \n",
            "partition the  jobs in the system into subsystems and to allocate the subsystems statically \n",
            "to particular processors.  \n",
            "• In such systems, jobs are moved between processors only when the system must be \n",
            "reconfigured such as when a processor fails,we call such systems, static  systems, because \n",
            "the system is statically configured . \n",
            "• If jobs on different processors are dependent the schedulers on the processors must \n",
            "synchronize the jobs according to some synchronization and resource access -control \n",
            "protocol.  \n",
            "• Otherwise, jobs on each processor are scheduled by themselves  \n",
            "For example we could do a static partitioning of the jobs in our priority -driven scheduling \n",
            "example.  \n",
            "• Put J1, J2, J3, J4 on P1 and the remaining jobs on P2. \n",
            "• The priority list is segmented into two parts:  \n",
            "• (J1, J2, J3, J4) used by the scheduler of processor P1  \n",
            "• (J5, J6, J7, J8) used by the scheduler of processor P2  \n",
            "• It is easy to see that the jobs on P1 complete by time 8 and the jobs on P2 complete by \n",
            "time 11.\n",
            "42 \n",
            " \n",
            "RTS \n",
            " • Also J2 completes by time 4 while J6 starts at time 6, thus the precedence constraint is \n",
            "satisfied.  \n",
            "In this example the response of the static system is just as good as that of the dynamic system.  \n",
            "Effective release times and deadlines:  \n",
            "• The given release times and deadlines are sometimes inco nsistent with the precedence \n",
            "constraints of the jobs.  \n",
            "– i.e. the release time of a job may be later than  that of  its successors, and its \n",
            "deadline may be earlier than that of its predecessors.  \n",
            "• Rather than working with the given release times and deadlines, we first derive a set of \n",
            "effective release times and deadlines from these timing constraints together with the \n",
            "given precedence constraints.  \n",
            "• These derived timing constraints are consistent with the precedence constraints.  \n",
            "– Effective Release Time : \n",
            "• The effective release time of a job without predecessors is equal to its \n",
            "given release time.  \n",
            "• The effective release time of a job with predecessors is equal to the \n",
            "maximum value among its given release time and the effective release \n",
            "times of all its predecessor s. \n",
            "– Effective Deadline : \n",
            "• The effective deadline of a job without a successor is equal to its given \n",
            "deadline.  \n",
            "• The effective deadline of a job with successors is equal to the minimum \n",
            "value among its given deadline and the effective deadlines of all of its \n",
            "successors.  \n",
            "The effective release times of all the jobs can be computed in one pass through the precedence \n",
            "graph in O( n2) time where n is the number of jobs.  Similarly for the effective deadlines.  \n",
            "• Consider the following example whose task graph is given in the following figure \n",
            "“example of effective timing constraints”\n",
            "43 \n",
            " \n",
            "RTS \n",
            "  \n",
            "• The numbers in brackets next to each job are its given release time and deadline.  \n",
            "• Because J1 and J2 have no predecessors, their effective release times are their given \n",
            "release times, 2 and 0 respectively.  \n",
            "• Similarly the effective release time of J3 ,J4, J5, J6, J7  are 2, 4, 2, 4, 6  \n",
            "Effective deadlines  \n",
            " J6 and J7 have no successors so their effective deadlines are their given deadlines, 20 and \n",
            "21 respectively.  \n",
            " Similarly the effective deadline of  J1, J2, J3  ,J4, J5 are 8, 7, 8, 9, 8  \n",
            " \n",
            " \n",
            "Earliest -Deadline -First (EDF) Algorithm:  \n",
            "A way to assign priorities to jobs is on the basis of their deadlines.  Earliest -Deadline -First (EDF) \n",
            "algorithm is based on the priority assignment whereby the earli er the deadline, the higher the \n",
            "priority.  This algorithm is important because it is optimal when used to schedule jobs on a \n",
            "proces sor when preemption is allowed and there is no contention for resources.  \n",
            "Theorem  \n",
            "When preemption is allowed and jobs do not contend for resources, the EDF algorithm can \n",
            "produce a feasible schedule of a set of jobs J with arbitrary release times and deadlines on a \n",
            "processor, if and only if J has feasible schedules.  \n",
            "• Any feasible schedule of J can be systematically transformed into an EDF schedule.\n",
            "44 \n",
            " \n",
            "RTS \n",
            " To see how we can look at the figure “Transformation of a non -EDF schedu le into an EDF \n",
            "schedule”  \n",
            "• Suppose that in a schedule parts of Ji and Jk are scheduled in intervals I1 and I2 \n",
            "respectively, and that deadline di  of Ji is later than deadline dk of Jk, but I1 is earlier than \n",
            "I2. \n",
            " \n",
            "There are two cases:  \n",
            "– First case  \n",
            "• The release time of Jk may be later than the end of I1. \n",
            "• Jk cannot be scheduled in I1. \n",
            "• The 2 jobs are already scheduled according to EDF.  \n",
            "– Second case  \n",
            "• The release time rk of Jk is before the end of I1.\n",
            "45 \n",
            " \n",
            "RTS \n",
            " • Without loss of generality we can assume that rk is no l ater than the \n",
            "beginning of I1. \n",
            "To transform the given schedule we swap Ji and Jk. \n",
            "• If I1 is shorter than I2, we move the portion of Jk that fits in I1 forward to I1 and move the \n",
            "entire portion of Ji scheduled in  I1 backward to I2 and place it after Jk. \n",
            "• Clearly, this swap is always possible.  \n",
            "• We can do a similar swap if I1 is longer than I2. \n",
            "• In which case we move the entire portion of Jk scheduled in I2 to I1 and place it before Ji \n",
            "and move the portion of Ji that fits in I2 to the interval.  \n",
            "• The result of t his swap is that these two jobs are now scheduled according to EDF.  \n",
            "• We repeat this transformation for every pair of jobs not scheduled according to EDF until \n",
            "no such pair exists.  \n",
            "The schedule so obtained may still not be an EDF schedule if some interval is  left idle while \n",
            "there are jobs ready for execution but scheduled later.  \n",
            "• This is illustrated in part (b) of the figure.  \n",
            "• We can eliminate such an idle interval by moving one or more of these jobs forward into \n",
            "the idle interval and leave the interval where the jobs were scheduled idle.  \n",
            "• Clearly this is always possible.  \n",
            "• We repeat this until the processor never idles when there are jobs ready for execution.  \n",
            "• This is illustrated in part (c) of the figure.  \n",
            "• This only works when there is preemption.  \n",
            "• This is because the preemptive EDF algorithm can always produce a feasible schedule if \n",
            "such a schedule exists.  \n",
            " \n",
            "LRT Algorithm Example:\n",
            "46 \n",
            " \n",
            "RTS \n",
            "  \n",
            "• In the above example, the number next to the job is the execution time and the feasible \n",
            "interval follows it.  \n",
            "• The latest deadline is 8, so time starts at 8 and goes back to 0.  At time 8, J2 is “ready” \n",
            "and is scheduled.  At time 7, J3 is also “ready” but because J2 has a later release time, it \n",
            "has a higher priority, so J2 is scheduled from 7 to 6.  \n",
            "• When J2 “completes” at time 6, J1 is “read y” however J3 has a higher priority so is \n",
            "scheduled from 6 to 4.  \n",
            "Finally J1 is scheduled from 4 to 1.  \n",
            "Least -Slack -Time -First (LST) Algorithm:  \n",
            "• Another algorithm optimal for scheduling preemptive jobs on one processor is  \n",
            "Least -Slack -Time -First (LST)  also called Minimum -Laxity -First (MLF).  \n",
            "• At any time t, the slack (or laxity) of a job with deadline d, is equal to d - t minus the time \n",
            "required to complete the remainder of the job.  \n",
            "• Job J1 from the LRT example is released at time 0 and has its deadline a t time 6 and \n",
            "execution time 3.  \n",
            "• Hence its slack is 3 at time 0.  \n",
            "• The job starts to execute at time 0.\n",
            "47 \n",
            " \n",
            "RTS \n",
            " • As long as it executes its slack remains 3 because at any time before its completion its \n",
            "slack is 6 - t - (3 - t) \n",
            "• Suppose J1 is preempted at time 2 by J3 which executes from time 2 to 4.  \n",
            "• During this interval the slack of J1 decreases from 3 to 1.  \n",
            "• At time 4 the remaining execution time of J1 is 1, so its slack is 6 - 4 - 1 = 1.  \n",
            "• The LST algorithm assigns priorities to jobs based on their slacks.  \n",
            "• The smaller the  slack, the higher the priority  \n",
            "Non-optimality of EDF and LST:  \n",
            "• Do EDF and LST algorithms remain optimal if preemption is not allowed or there is \n",
            "more than one processor?  \n",
            "No!   \n",
            "Consider the following 3 independent non -preemptable jobs, J1, J2, J3, with rele ase times 0, 2, 4 \n",
            "and execution times 3, 6, 4, and deadlines 10, 14, 12 respectively.  \n",
            "• Both EDF and LST would produce the infeasible schedule (a) whereas a feasible \n",
            "schedule is possible (b).  \n",
            "• Note that (b) cannot be produced by a priority driven algorithm\n",
            "48 \n",
            " \n",
            "RTS \n",
            "  \n",
            "Non-optimality of EDF for multiprocessors:  \n",
            "• This time we have two processors and three jobs J1, J2, J3, with execution times 1, 1, 5 \n",
            "and deadlines 1, 2, 5 respectively.  All with release time 0.  \n",
            "• EDF gives the infeasible schedule (a) whereas LST gives a feas ible schedule (b) but in \n",
            "general LST is also non -optimal for multiprocessors.\n",
            "49 \n",
            " \n",
            "RTS \n",
            " VALIDATING TIMING CONSTRAINTS IN PRIORITY -DRIVEN SYSTEMS  \n",
            "• Compared with the clock -driven approach, the priority -driven scheduling approach has \n",
            "many advantages:  \n",
            "– Easy to implement  \n",
            "– Often have simple priority assignment rules  \n",
            "– If the priority assignment rules are simple, the run -time overheads of maintaining \n",
            "priority queues can be small  \n",
            "– Does not require information about deadlines and release times in advance so it is \n",
            "suited to applications with varying time and resource requirements  \n",
            "• On the other hand a clock -driven scheduler:  \n",
            "Requires information about release times and deadlines of jobs in advance in order to \n",
            "schedule them  \n",
            "Despite its merits, the priority -driven approach has  not been widely used in hard real -time \n",
            "systems, especially safety -critical systems, until recently.  \n",
            "• The main reason for this is that the timing behaviour of a priority -driven system is not \n",
            "deterministic when job parameters vary.  \n",
            "• Thus it is difficult to va lidate that the deadlines of all jobs scheduled in a priority -driven \n",
            "manner indeed meet their deadlines when job parameters vary.  \n",
            "What is the  validation problem ?  \n",
            "• Given a set of jobs, the set of resources available to the jobs, and the scheduling \n",
            "(and res ource access -control) algorithm to allocate processors and resources to \n",
            "jobs, determine whether all the jobs meet their deadlines.  \n",
            "This is a very difficult problem to solve when you don‟t have all the information about all \n",
            "the jobs available in advance and  can verify the complete schedule as in a clock -driven \n",
            "system  \n",
            "ANOMALOUS BEHAVIOUR OF PRIORITY -DRIVEN SYSTEMS  \n",
            "Consider the example in figure “illustrating scheduling anomalies”\n",
            "50 \n",
            " \n",
            "RTS \n",
            "  \n",
            " \n",
            "This example illustrates why the validation problem is difficult with priorit y-driven scheduling \n",
            "and varying job parameters.  \n",
            "• Consider a simple system of four independent jobs scheduled on two processors in a \n",
            "priority -driven manner.  \n",
            "• There is a common priority queue and the priority order of jobs is J1, J2, J3, J4, with J1 \n",
            "being of highest priority.  \n",
            "• It is a dynamic system.  \n",
            "• Jobs may be preempted but never migrated to another processor. (a common \n",
            "characteristic)  \n",
            "• The release times, deadlines and execution times or the jobs are provided in the table.  \n",
            "• The execution times of the jobs are fixed except for J2 whose execution time is \n",
            "somewhere in the range [2,6]  \n",
            "Suppose we want to determine whether the system meets all the deadlines and whether the \n",
            "completion -time jitter of every job  (i.e. the difference between the latest and earli est completion \n",
            "times of the job) is <= 4.\n",
            "51 \n",
            " \n",
            "RTS \n",
            " • Let us simulate the possible schedules to see what can happen.  \n",
            "• Suppose we schedule the jobs according to their priorities and try out J2 with its \n",
            "maximum execution time 6 and also with its minimum execution time 2.   (see the figure \n",
            "(a),(b))  \n",
            "• It seems OK for deadlines and for completion -time jitter.  \n",
            "Wrong!   Have a look at cases (c) and (d)  \n",
            "• As far as J4 is concerned, the worst -case schedule is (c) when execution time of J2 is 3 \n",
            "and J4 completes at 21 missing the deadl ine. \n",
            "• The best -case schedule for J4 is (d) when J2 has execution time 5 and J4 completes at time \n",
            "15, however the completion time jitter exceeds its limit of 4.  \n",
            "• This is known as a scheduling anomaly, an unexpected timing behaviour of priority -\n",
            "driven systems.  \n",
            "PREDICTABILITY OF EXECUTIONS  \n",
            "To define predictability more formally, we call the schedule of J produced by the given \n",
            "scheduling algorithm when the execution time of every job has its maximum value the maximal \n",
            "schedule of J. Similarly, the schedule of J produced by the given scheduling algorithm when the \n",
            "execution time of every job has its minimum value is the minimal schedule . When the execution \n",
            "time of every job has its actual value, the resultant schedule is the actual schedule of J. So, the \n",
            "schedules in above figure (a) and (b) are the maximal and minimal schedules, respectively, of the \n",
            "jobs in that system, and all the schedules shown in the figure are possible actual schedules.  \n",
            "Let s(Ji ) is the (actual) start time of Ji. Let s+(Ji ) and s−(Ji ) be the start times of Ji according to \n",
            "the maximal schedule and minimal schedule of J, respectively . We say that Ji is start-time \n",
            "predictable  if s−(Ji ) ≤ s(Ji ) ≤ s+(Ji ). As an example, for the job J4 in Figure above  s−(J4) is 2. \n",
            "s+(J4) is 6. Its actual start time is in the range [2, 6]. Therefore, J4 is start -time predictable. \n",
            "Similarly, let f (Ji ) be the actual completion time (also called finishing time) of Ji according to \n",
            "the actual schedule of J. Let f +(Ji) and f −(Ji ) be the completion times of Ji according to the \n",
            "maximal schedule and minimal schedule of J, respectively. We say that Ji is completion -time \n",
            "predictable if f −(Ji ) ≤ f (Ji ) ≤ f +(Ji ). The execution of Ji is predictable , or simply Ji is \n",
            "predictable, if Ji is both start -time and comp letion -time predictable. The execution behavior of \n",
            "the entire set J is predictable if every job in J is predictable. From figure above , we see that f –\n",
            "52 \n",
            " \n",
            "RTS \n",
            " (J4) is 20, but f +(J4) is 16. It is impossible for the inequality  20 ≤ f (J4) ≤ 16 to hold. Therefore, \n",
            "J4 is not completion -time predictable, and the system is not predictable.  \n",
            " \n",
            "Priority -Driven Systems and Priority Inversion:  \n",
            "• Note that in our example of anomalous behaviour, it is possible to obtain valid schedules.  \n",
            "It is just that our priority -driven algorithms could not do it.  \n",
            "• For instance, if one assumed that J4 was not preemptable, then case © would meet its \n",
            "deadline, but you would be violating the rule that says that the highest priority runnable \n",
            "job should be run.  \n",
            "• In this case J4 would continue r unning even though the higher priority J3 was able to run.  \n",
            "• This is called a priority -inversion . \n",
            "• This happens when a lower priority job runs in preference to a higher priority job which \n",
            "has to wait.  \n",
            "OFF -LINE VERSUS ON -LINE SCHEDULING  \n",
            " \n",
            "This schedule is compu ted off -line before the system begins to execute, and the computation is \n",
            "based on the  knowledge of the release times and processor -time/resource requirements of all the \n",
            "jobs for all times. When the  operation mode of the system changes, the new schedule specifyin g \n",
            "when each job in the new mode executes is also precomputed and stored for use. In this case, w e \n",
            "say that scheduling is (done) off-line, and the precomputed schedules are off-line schedules . This \n",
            "approach is possible only when the system is deter ministic, meaning that the sy stem provides \n",
            "some fixed set(s) of functions and that the release times and processor -time/resource demand s of \n",
            "all its jobs are known and do not vary or vary only slightly.   \n",
            "Scheduling is done on-line, or that we use an on-line scheduling algorithm , if the scheduler  \n",
            "makes each scheduling decision without knowledge about the jobs that will be released in the  \n",
            "future; the parameters of each job become known to the on -line scheduler only after the job i s \n",
            "released. The priority -drive n algorithms described earlier and in subsequent chapters are  on-line \n",
            "algorithms. Clearly, on -line scheduling is the only option in a system whose future workload is \n",
            "unpredictable. An on -line scheduler can accommodate dynamic variations in user demands and \n",
            "resource availability. Witho ut prior knowledge about future jobs, the scheduler cannot make \n",
            "optimal scheduling decision s while a clairvoyant scheduler that knows about all future jobs can.\n",
            "1  \n",
            " \n",
            "Chapter 5  \n",
            "Clock Driven Scheduling  \n",
            "Assumptions and notation for clock -driven scheduling  \n",
            "1. There is a constant number n periodic tasks in the system.  \n",
            "2. The parameters of all periodic tasks are known a priori.  \n",
            "-release times of jobs are  negligibly small.  \n",
            "Ti is released pi units of time after the previous job in Ti. \n",
            "3. Each job Ji,k is ready for execution at its release time ri,k. \n",
            " \n",
            "n special queue.  \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Notations:  \n",
            "• The 4 -tuple Ti = (φi, pi, ei, Di) refers to a periodic task Ti with phase φ i, period pi, execution \n",
            "time ei, and relative deadline Di. \n",
            "– Default phase of Ti is φi = 0, default relative deadline is the period Di = pi. \n",
            "– Omit elements of the tuple that have default values . \n",
            "Example:  \n",
            "i) T1 = (1, 10, 3, 6) ⇒ φ1 = 1 , p1 = 10,  e1 = 3 , D1 = 6  \n",
            "J1,1 released at 1, deadline 7  \n",
            "J1,2 released at 11, deadline 17  \n",
            "ii) T2 = (10, 3, 6) ⇒ φ2 = 0 ,  p2 = 10 , e2 = 3 ,  \n",
            "D2 = 6  J2,1 released at 0, deadline 6  \n",
            "J2,2 released at 10 and so \n",
            "on…. deadline 16\n",
            "2  \n",
            " \n",
            " \n",
            "iii) T3 = (10, 3) ⇒ φ3 = 0, p3 = 10, e3 = 3,  \n",
            "D3 = 10.  \n",
            " \n",
            "Static, Clock -Driven Scheduler : \n",
            " Static schedule can be calculated off -line (all parameters are known at start).  \n",
            " Can use c omplex algorithms can be used . Run-time of the scheduling algorithm \n",
            "irrelevant . \n",
            "  Amount of processor time allocated to each job is equal to its maximum execution tim e. \n",
            " Static schedule guarantees that every job completes by its deadline as long as no job \n",
            "overruns.  \n",
            " Scheduler dispatches jobs according to the static schedule, repeating each  hyper period . \n",
            "Example:  \n",
            "Four independent periodic tasks: T1 = (4,1),  T2 = (5, 1.8) , T3 = (20, 1), T4 = (20, 2)  \n",
            " \n",
            "  \n",
            " \n",
            "Fig  . One possible schedule  \n",
            "Slack time can be used to execute aperiodic jobs  \n",
            "Another example  : Consider a system with 4 independent p eriodic tasks:  \n",
            "– T1 = ( 4  , 1.0) ,  T2 = ( 5  , 1.8) , T3 = (20, 1.0)  , T4 = (20, 2.0)  [Phase and deadline take default \n",
            "values]  here first value represents period and next represents execution time.  \n",
            "J3,1 released at 0, deadline 10  \n",
            "J3,2 released at 10, deadline 20\n",
            "3  \n",
            " \n",
            "Hyper -period H = 20 (least common multiple of 4, 5, 20, 20)  \n",
            "• Can construct an arbitrary static schedule to meet all deadlines:  \n",
            " \n",
            "Types of Clock Driven Schedules:   \n",
            " Table driven and  \n",
            "    Cyclic Schedules.  \n",
            " Table driven Scheduling : Table driven schedulers usually pre -compute which task would \n",
            "run when and store this sc hedule in a table at the time the system is designed. Rather than \n",
            "automatic computation of schedule by the scheduler, the application programmer can be \n",
            "given the freedom to select his own schedule for the set of tasks in the application and store \n",
            "the sched ule in a table (called schedule table) to be used by the scheduler at the run time. An \n",
            "example of a schedule table is shown as following fig.  \n",
            "Tasks  Start time in \n",
            "millisecond  \n",
            "T1 0 \n",
            "T2 3 \n",
            "T3 10 \n",
            "T4 12 \n",
            "T5 17 \n",
            "Fig. An example of table driven scheduling  \n",
            "Thin k :::   What would be the size of schedule table required for a given set of periodic real \n",
            "time tasks to be run on a system?\n",
            "4  \n",
            " \n",
            "Cyclic Schedule:  \n",
            "Cyclic schedules are very popular and extensively used in industry. Cyclic schedules are simple, \n",
            "efficient and are  easy to program. An example application where cyclic schedule is used, is a \n",
            "temperature controller.  A temperature controller periodically samples the temperature of a room \n",
            "and maintains it at a preset value. Such temperature controllers are embedded in ty pical \n",
            "computer -controlled air conditioners . \n",
            "Tasks  Frame \n",
            "Number  \n",
            "T3 F1 \n",
            "T1 F2 \n",
            "T3 F3 \n",
            "T4 F2 \n",
            "                         Fig. Example schedule table for cyclic scheduler  \n",
            "A cyclic scheduler repeats a pre -computed schedule. The pre -computed schedule needs to be \n",
            "stored only for one major cycle.  \n",
            "General structure of cyclic schedules:  \n",
            "Arbitrary table -driven cyclic schedules flexible, but inefficient  \n",
            "– Relies on accurate timer interrupts, based on execution times of tasks  \n",
            "– High scheduling overhead  \n",
            "Easier to implemen t if structure imposed:  \n",
            " Make scheduling decisions at periodic intervals ( frames ) of length f \n",
            " Execute a fixed list of jobs with each frame, disallowing pre -emption except at frame boundaries  \n",
            " Require phase of each periodic task to be a non -negative integer m ultiple of the frame size.  \n",
            "• The first job of every task is released at the beginning of a frame  \n",
            "• φ = k⋅f where k is a non -negative integer  \n",
            "Gives two benefits:\n",
            "5  \n",
            " \n",
            "– Scheduler can easily check for overruns and missed deadlines at the end of  each frame . \n",
            "– Can use a periodic clock inte rrupt, rather than programmable timer . \n",
            " \n",
            "Frame Size Constraints : \n",
            "How to c hoose frame length?  \n",
            "-To avoid preemption, want jobs to start and complete execution within a  single frame:  \n",
            " \n",
            "f  ≥ max( e1, e2, …, en)  ………………    (Eq.1)  \n",
            " \n",
            "– To minimize the number of entries in the c yclic schedule, the hyper -period should be an integer \n",
            "multiple  of the frame size ( ⇒ f divides evenly into the  period of at least one task):  \n",
            " \n",
            "∃ i : mod( pi, f ) = 0 …………………………………………………. (Eq.2)  \n",
            " \n",
            "– To allow scheduler to check that jobs complete by their deadline   , should be  at least one frame  \n",
            "boundary between release ti me of a job and its deadline:  \n",
            " \n",
            "2*f – gcd(pi, f ) ≤ Di for i = 1, 2, …, n…………………………………………………….  (Eq.3)  \n",
            " \n",
            "All 3 constraints should be satisfied ……….!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!  \n",
            " \n",
            "Frame Size Constraints – Example  1: \n",
            "Given tasks are T1 = (4, 1.0), T2 = (5, 1.8) T3 = (20, 1.0), T4 = (20, 2.0).  \n",
            "Hyper -period H = lcm (4, 5, 20, 20) = 20  \n",
            "Constraints: Eq.1 ⇒ f ≥ max (1, 1.8, 1, 2) ≥ 2  \n",
            "Eq.2 ⇒ f ∈ { 2, 4, 5, 10, 20 }  \n",
            " \n",
            "Eq.3 ⇒ 2f - gcd( 4, f ) ≤ 4  (T1) \n",
            "2f - gcd( 5, f ) ≤ 5   (T2) \n",
            "2f - gcd(20, f ) ≤ 20   (T3, T4)\n",
            "6  \n",
            " \n",
            "The value s that satisfie s all constraints are f = 2 or 4.  \n",
            " \n",
            " \n",
            "Example 2:  \n",
            "Task set:  \n",
            "             ( Pi , ei , Di ) \n",
            "T1: (15, 1, 14)  \n",
            "T2:  (20, 2, 26)  \n",
            "T3: (22, 3, 22)  \n",
            "   \n",
            " \n",
            "Job Slices:  \n",
            " Sometimes, a system cannot meet all three frame size constraints  simultaneously . \n",
            " Can of ten solve by partitioning a job with large execution time  into slices (sub -jobs) with shorter \n",
            "execution times/deadlines . Consider a system with T1 = (4, 1), T2 = (5, 2, 7), T3 = (20, 5)  \n",
            "– Cannot satisfy constraints: Eq.1 ⇒ f ≥ 5 but Eq.3 ⇒ f ≤ 4 \n",
            "– Solve by splitting T3 into T3,1 = (20, 1), T3,2 = (20, 3) and T3,3 = (20,1)  \n",
            "- Other possible splits exist; pick based on application domain knowledge  \n",
            "– Result can be scheduled with f = 4\n",
            "7  \n",
            " \n",
            "A Cyclic Executive  \n",
            " Modify previous table -driven cyclic scheduler to be frame base schedule all types of jobs in \n",
            "multi -threaded system .  \n",
            " Table that drives the scheduler has F entries, where  F= H/f  \n",
            "– Each corresponding entry L(k) lists the names of the job slices that are  scheduled to \n",
            "execute in fr ame k; called a scheduling block . \n",
            "– Each job slice implemented by a procedure, to be called in turn . \n",
            "• Cyclic executive executed by the clock interrupt that signals the  start of a frame:  \n",
            "– Determines the appropriate scheduling block for this frame . \n",
            "– Execu tes the jobs in the scheduling block in order . \n",
            "– Starts job at head of the aperiodic job queue running for remainder of  frame . \n",
            "• Less overhead than pure table driven cyclic scheduler, since only  interrupted on frame \n",
            "boundaries, rather than on each job . \n",
            " \n",
            "Improving the average response time of  Aperiodic Jobs:  \n",
            " So far aperiodic jobs have been scheduled in the background after all other job slices \n",
            "have been completed, it causes av erage response time is long . \n",
            " Average response time for aperiodic jobs can be impro ved by scheduling hard -real time \n",
            "jobs as late as possible without missing the deadline.  \n",
            " \n",
            "Slack Stealing:  \n",
            "A natural way to improve the response times of aperiodic jobs is by executing the aperiodic  jobs \n",
            "ahead of the periodic jobs whenever possible. This app roach, called slack stealing ,was originally \n",
            "proposed for priority -driven systems . For the slack -stealing scheme to work, every periodic job \n",
            "slice must be scheduled in a frame that ends no  later than its deadline. Let the total amount of \n",
            "time allocated to all the slices scheduled in the frame k be xk. The slack (time) available in the \n",
            "frame is equal to f − xk at the beginning of the frame. If the aperiodic job queue is nonempty at \n",
            "this time, the cyclic executive can let aperiodic jobs execute for this amoun t of time without \n",
            "causing any job to miss its deadline.\n",
            "8  \n",
            " \n",
            "When an aperiodic job executes ahead of slices of periodic tasks, it consumes the slack in the \n",
            "frame. After y units of slack time are used by aperiodic jobs, the available slack is reduced to f − \n",
            "xk − y. The cyclic executive can let aperiodic jobs execute in frame k as long as there is slack, \n",
            "that is, the available slack f − xk − y in the frame is larger than 0.  \n",
            " \n",
            "When the cyclic executive finds the aperiodic job queue empty, it lets the periodic task s erver \n",
            "execute the next slice in the current block. The amount of slack remains the same during this \n",
            "execution. As long as there is slack, the cyclic executive returns to examine the aperiodic job \n",
            "queue after each slice completes.  \n",
            " \n",
            " \n",
            " Interval timer is used.  \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Example:\n",
            "9  \n",
            " \n",
            " \n",
            "Fig. example illustrating slack stealing  \n",
            " \n",
            " \n",
            "SCHEDULING SPORADIC  JOBS  \n",
            "Like jobs in periodic tasks, sporadic jobs have hard deadlines. On the other hand, their minimum  \n",
            "release times and maximum execution times are unknown a priori. Consequently, it is  impossible \n",
            "to guarantee a priori that all sporadic jobs can complete in time.  \n",
            " \n",
            "Acceptance Test  \n",
            "A common way to deal with this situation is to have the scheduler perform an acceptance test  \n",
            "when each sporadic job is released. During an acceptance test , the scheduler checks whether  the \n",
            "newly released sporadic job can be feasib ly scheduled with all the jobs in the system at the  time. \n",
            "Here, by a job in the system , we mean either a periodic job, for which time has already  been \n",
            "allocated in the precomputed cyclic schedule, or a sporadic job which has been scheduled  but not \n",
            "yet comp leted. If according to the existing schedule, there is a sufficient amount of  time in the \n",
            "frames before its deadline to complete the newly released sporadic job without  causing any job\n",
            "10  \n",
            " \n",
            "in the system to complete too late, the scheduler accepts and schedules  the job. Otherwise, the \n",
            "scheduler rejects the new sporadic job.  \n",
            " \n",
            "Conceptually, it is quite simple to do an acceptance test. To explain, let us suppose that  at the \n",
            "beginning of frame t , an acceptance test is done on a sporadic job S(d, e) , with deadline  d and \n",
            "(maximum) execution time e. (When it is not necessary to mention the deadline and  execution \n",
            "time of the job, we will simply refer to it as S without these parameters.) Suppose  that the \n",
            "deadline d of S is in frame l+1 (i.e., frame l ends before d but frame l+1 ends after d) and l ≥ t . \n",
            "Clearly, the job must be scheduled in the lth or earlier frames. The job can complete  in time only \n",
            "if the current (total) amount of slack time ζc(t, l) in frames t, t+1, . . . l is equal to  or greater than \n",
            "its execution time e. Therefore, the scheduler should reject S if e > ζc(t, l) .  \n",
            " \n",
            "As we will see shortly, the scheduler may let a new sporadic job execute ahead of some \n",
            "previously  accepted sporadic jobs. Therefore, the scheduler also checks whether accepting the \n",
            "new job  may cause some sporadic jobs in the system to complete late. The scheduler accepts the \n",
            "new job S(d, e) only if e ≤ ζc(t, l) and no sporadic jobs in system are adversely affected.  \n",
            " \n",
            "EDF Scheduling of the Accepted Jobs : \n",
            "By virtue of its optimality, the EDF a lgorithm is a good way to schedule accepted sporadic  jobs. \n",
            "For this purpose, the scheduler maintains a queue of accepted sporadic jobs in nondecreasing  \n",
            "order of their deadlines and inserts each newly accepted sporadic job into this queue  in this \n",
            "order. Whe never all the slices of periodic tasks scheduled in each frame are completed,  the cyclic \n",
            "executive lets the jobs in the sporadic job queue execute in the order they appear  in the queue.  \n",
            "The scheduler allows aperiodic jobs to execute only  when the accepted sporadic job queue is \n",
            "empty.  Following f igure gives an example. The frame size used here is 4. The shaded boxes \n",
            "show  where periodic tasks are scheduled .\n",
            "11  \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Description :  \n",
            "Suppose that at time 3, a sporadic job S1(17, 4.5) with execution time 4.5 and de adline  17 is \n",
            "released. The acceptance test on this job is done at time 4, that is, the beginning of  frame 2. S1 \n",
            "must be scheduled in frames 2, 3, and 4. In these frames, the total amount  of slack time is only 4, \n",
            "which is smaller than the execution time of S1. Consequently,  the scheduler rejects the job.  \n",
            " \n",
            "• At time 5, S2 (29, 4) is released. Frames 3 through 7 end before its deadline. During the  \n",
            "acceptance test at 8, the scheduler finds that the total amount of slack in these frames  is 5.5. \n",
            "Hence, it accepts  S2. The first part of S2 with execution time 2 executes in the  current frame.  \n",
            " \n",
            "• At time 11, S3(22, 1.5) is released. At time 12, the scheduler finds 2 units of slack time  in \n",
            "frames 4 and 5, where S3 can be scheduled. Moreover, there still is enough slack  to complete S2 \n",
            "even though S3 executes ahead of S2. Consequently, the scheduler accepts  S3. This job executes \n",
            "in frame 4.  \n",
            " \n",
            "• Suppose that at time 14, S4 (44, 5) is released. At time 16 when the acceptance test is  done, the \n",
            "scheduler finds only 4.5 units o f time available in frames before the deadline  of S4, after it has\n",
            "12  \n",
            " \n",
            "accounted for the slack time that has already been committed to the  remaining portions of S2 and \n",
            "S3. Therefore, it rejects S4. When the remaining portion  of S3 completes in the current fram e, S2 \n",
            "executes until the beginning of the next frame . \n",
            " The last portion of S2 executes in frames 6 and 7.  \n",
            " \n",
            "ALGORITHM FOR CONSTRUCTING STATIC SCHEDULES  \n",
            "The general problem of choosing a frame length for a given set  of periodic tasks, segmenting the \n",
            "tasks if necessary, and  scheduling the tasks to meet all their deadlines is NP-hard.  \n",
            "• In the special case of independent preemptable tasks,  a polynomial -time solution is based on \n",
            "the Iterative Network Flow  algorithm (INF algorithm).  \n",
            "• A system of  independent preem ptable periodic tasks  whose  relative deadlines are not less than \n",
            "their respective periods is  schedulable iff the total utilization of the tasks is ≤ 1.  \n",
            "- if some relative deadlines are shorter than the period, a  feasible schedule may not exist even \n",
            "when U ≤ 1. \n",
            "The INF algorithm is performed in 2 steps : \n",
            "- step 1:  find all the possible frame sizes of the system that  meet the frame size constraints 2 and \n",
            "3  but not  necessarily constraint 1;  \n",
            "- step 2: apply INF algorithm starting with the largest possible  frame . \n",
            "• Example (slide 11):  \n",
            "- T1 = (4,1); T2 = (5,2,7) and T3 = (20,5)  \n",
            "- frame sizes 2 and 4 meet constraints 2 and 3, but not 1.  \n",
            "• The INF algorithm iteratively tries to find a feasible cyclic  schedule of the system for a possible \n",
            "frame size at a time,  starti ng with the largest value.  \n",
            " \n",
            "Network -Flow Graph:  \n",
            "The algorithm used during each iteration is based on the wellknown network -flow formulation of \n",
            "the preemptive scheduling problem. In the description of this formulation, it is more convenient \n",
            "to ignore the ta sks to which the jobs belong and name the jobs to be scheduled in a major cycle \n",
            "of F frames J1, J2, . . . , JN . The constraints on when the jobs can be scheduled are represented \n",
            "by the network -flow graph of the system.\n",
            "13  \n",
            " \n",
            "This graph contains the following ve rtices and edges; the capacity of an edge is a nonnegative  \n",
            "number associated with the edge.  \n",
            " \n",
            "1. There is a job vertex Ji  representing each job Ji, for i = 1, 2, . . . , N . \n",
            "2. There is a frame vertex  named j representing each frame j in the major cycle, for  j = 1, 2, . . . , \n",
            "F. \n",
            "3. There are two special vertices named source  and sink. \n",
            "4. There is a directed edge (Ji , j ) from a job vertex Ji to a frame vertex j if the job Ji can be \n",
            "scheduled in the frame j , and the capacity of the edge is the frame size f . \n",
            "5. There is a directed edge from the source vertex to every job vertex Ji , and the capacity of this \n",
            "edge is the execution time ei of the job.  \n",
            "6. There is a directed edge from every frame vertex to the sink, and the capacity of this  \n",
            "edge is f .\n",
            "14\n",
            "15  \n",
            " \n",
            " \n",
            " \n",
            "Practical Considerations : \n",
            " Handling overruns:  \n",
            "- Jobs are scheduled based on maximum execution time, but failures might  cause \n",
            "overrun . \n",
            "- A robust system will handle this by either: 1) killing the job and starting an  error \n",
            "recovery task; or 2) preempting the jo b and scheduling the remainder  as an \n",
            "aperiodic job . \n",
            "- Depends on usefulness of late results, dependencies between jobs, etc.  \n",
            " \n",
            " Mode changes:  \n",
            "- A cyclic scheduler needs to know all parameters of real -time jobs a priori . \n",
            "- Switching between modes of operation impli es reconfiguring the \n",
            "scheduler  and bringing in the code/data for the new jobs . \n",
            "- This can take a long time: schedule the reconfiguration job as an aperiodic  \n",
            "or sporadic task to ensure other deadlines met during mode change.  \n",
            " Multiple processors:  \n",
            "Can be handl ed, but off -line scheduling table generation more complex .\n",
            "16  \n",
            " \n",
            "Pros and Cons of Clock driven Scheduling:  \n",
            " Conceptual simplicity  \n",
            "- Ability to consider complex dependencies, communication delays, and \n",
            "resource contention among jobs when constructing the static sch edule  , \n",
            "guaranteeing absence of deadlocks and unpredictable delays.  \n",
            "- Entire schedule is captured in a static table.  \n",
            "- Different operating modes can be represented by different tables.  \n",
            "- No concurrency control or synchronization required.  \n",
            "- If completion time jitt er requirements exist, can be captured in the \n",
            "schedule.  \n",
            " When workload is mostly periodic and the schedule is cyclic, timing constraints can be \n",
            "checked and enforced at each frame boundary.  \n",
            " Choice of frame size can minimize context switching and communicatio n overheads.  \n",
            " Relatively easy to validate, test and certify.  \n",
            " \n",
            "Cons:  \n",
            " Inflexible  \n",
            "- Pre-compilation of knowledge into scheduling tables means that if  \n",
            "anything changes materially, have to redo the table generation . \n",
            "- Best suited for systems which are rarely modifie d once built . \n",
            " Other disadvantages:  \n",
            "- Release times of all jobs must be fixed . \n",
            "- All possible combinations of periodic tasks that can execute at the same  \n",
            "time must be known a priori, so that the combined schedule can be pre -\n",
            "computed .\n",
            "17  \n",
            " \n",
            " \n",
            "CHAPTER 6  \n",
            "Priority -Driv en Scheduling of Periodic Tasks:  \n",
            " \n",
            " Assumptions  \n",
            " The tasks are independent and . \n",
            " There are no aperiodic and sporadic tasks . \n",
            " Every job is ready for execution as soon as it is released,  \n",
            "  Every job can be preempted at any time, and never suspends itself,  \n",
            "  Schedu ling decisions are made immediately upon job releases and  completions,  \n",
            "  Context switch overhead is negligible  \n",
            " Fixed number of periodic tasks,  \n",
            " Scheduling on uniprocessor systems  \n",
            " \n",
            "Multiprocessor Scheduling  \n",
            " Dynamic vs.  Static  \n",
            "A multiprocessor priority -driven  system is either dynamic or static. In  a static system, all the \n",
            "tasks are partitioned into subsystems. Each subsystem is assigned to a  processor, and tasks on \n",
            "each processor are scheduled by themselves. In contrast, in a dynamic  system, jobs ready for \n",
            "execution are placed in one common priority queue and dispatched to  processors for execution as \n",
            "the processors become available.\n",
            "18  \n",
            " \n",
            " \n",
            "Why not dynamic multiprocessor scheduling?  \n",
            "In most cases, dynamic systems perform better than static systems but we don’t  know how to \n",
            "determine the worst case performance i.e. the  performance of priority driven algorithms can be \n",
            "unacceptably poor. For this reason most hard real time systems are static systems.  \n",
            " \n",
            "Example showing poor performance of priority driven systems:  \n",
            "Consider m+1 periodic independent tasks, Ti = (period or relative deadline, execution time) = \n",
            "(1,2ε) for 1 to m tasks (i.e. first tasks) and for m+1 th task T m+1 = ( 1+  ε, 1) .Here Di = p i and phase \n",
            "= 0. Priorities are assigned in EDF basis.  \n",
            " \n",
            "Fig. A dynamic EDF sc hedule on m processors  \n",
            " \n",
            "The first job Jm+1,1 in Tm+1 has the lowest priority because it has the latest deadline.\n",
            "19  \n",
            " \n",
            "Here we see that Jm+1,1  doesnot complete  until 1+2  ε and hence misses its deadline.  \n",
            "Total utilization =  m (2 ε/1) + 1/(1+ ε )= 2m ε/1 + 1/(1+  ε) = 2mε +1/(1+ ε).  \n",
            "In the limit as ε approaches zero, U approaches 1, and yet the system remains unschedulable.  We would \n",
            "get the same infeasible schedule if we assigned the same priority to all the jobs in each task according to \n",
            "the period of the task: t he shorter the period, the higher the priority. On the other hand, this system can be \n",
            "feasibly scheduled statically. As long as the total utilization of the first m tasks, 2 mε, is equal to or less \n",
            "than 1, this system can be feasibly scheduled on two proces sors if we put Tm+1 on one processor and the \n",
            "other tasks on the other processor and schedule the task(s) on each processor according to either of these \n",
            "priority -driven algorithms.  \n",
            " \n",
            "Fixed Priority vs. Dynamic Priority Algorithms:  \n",
            "Priority -driven algorithms differ from each other in how priorities are assigned to jobs. We \n",
            "classify algorithms for scheduling periodic tasks into two types: fixed priority and dynamic \n",
            "priority.  \n",
            "A fixed -priority algorithm assigns the same priority to all the jobs in each task. In other words, \n",
            "the priority of each periodic task is fixed relative to other tasks. In contrast, a dynamic -priority \n",
            "algorithm assigns different priorities to the individual jobs in each task. Hence the priority of the \n",
            "task with respect to that of the other t asks changes as jobs are released and completed. This is \n",
            "why this type of algorithm is said to be “dynamic.”  \n",
            "Indeed, we have three categories of algorithms:  \n",
            " fixed -priority algorithms, Rate Monotonic (RM) , Deadline Monotonic(DM).  \n",
            " task-level dynamic -priori ty (and job  level fixed -priority) algorithms EDF, FIFO, LIFO  \n",
            " job-level (and task -level) dynamic algorithms: LST , RR  \n",
            "Except where stated otherwise, by dynamic -priority algorithms, we mean task -level \n",
            "dynamic -priority (and job -level fixed -priority) algorithm s. \n",
            " \n",
            "Rate Monotonic:\n",
            "20  \n",
            " \n",
            "- The rate (of job releases) of a task = 1/period.  \n",
            "- The higher its rate, the higher the priority of the task.  \n",
            "For  example: (a): T1 = (4,1); T2 = (5,2); T3 = (20,5) .  \n",
            " \n",
            "Rate( T1 )=1/4= .25  \n",
            "Rate(T2)= 1/5=.2  \n",
            "Rate(T3)=1/20=.05 ,  Therefore T1 has highest priority.  \n",
            "The RM schedule is :  \n",
            " \n",
            "Example (b): T1 = (2,0.9); T2 = (5,2.3)  \n",
            "The schedule is  :  \n",
            " \n",
            " \n",
            "Deadline Monotonic:  \n",
            " Well known fixed priority algorithm.  \n",
            " The shorter its relative deadline, the higher the priority of the task.  \n",
            "T1 = (50,50,25,1 00); T2 = (0,62.5,10,20); T3 = (0,125,25,50)  \n",
            "u1 = 0.5; u2 = 0.16; u3 = 0.2 => U = 0.86; H = 250.\n",
            "21  \n",
            " \n",
            "-(a) DM algorithm: feasible\n",
            " \n",
            "- (b) RM algorithm: not feasible  => schedule not optimal  \n",
            "Earliest -Deadline -First (EDF):  \n",
            "The earlier its absolute deadline, the h igher the priority of the job . \n",
            " \n",
            " \n",
            "Fig. An earliest -deadline -first schedule of (2, 0.9) and (5, 2.3)  \n",
            "Description:  \n",
            "-At time 0, the first jobs J1,1 and J2,1 of both tasks are ready. The (absolute) deadline of J1,1 is  \n",
            "= r+D=0+2= 2 while the deadline of J2,1 is= 0+5=5. Consequently, J1,1 has a higher priority \n",
            "and executes. When J1,1 completes, J2,1 begins to execute.\n",
            "22  \n",
            " \n",
            "• At time 2, J1,2 is released, and its deadline is 4, earlier than the deadline of J2,1. Hence, J1,2 is \n",
            "placed ahead of J2,1 in the ready job queu e. J1,2 preempts J2,1 and executes.  \n",
            "• At time 2.9, J1,2 completes. The processor then executes J2,1 \n",
            "At time 4, J1,3 is released; its deadline is 6, which is later than the deadline of J2,1. \n",
            "Hence, the processor continues to execute J2,1. \n",
            "• At time 4.1, J2,1 completes, the processor starts to execute J1,3, and so on.  \n",
            "(Refer hand  note for detail)  \n",
            "Hw# Explain when DM and RM are identical and when differ?  \n",
            "MAXIMUM SCHEDULABLE UTILIZATION  \n",
            "we say that a system is schedulable by an algorithm if the algorithm always  produces a feasible \n",
            "schedule of the system. A system is schedulable (and feasible ) if it is schedulable by some \n",
            "algorithm, that is, feasible schedules of the system exist.  \n",
            "Schedulable Utilizations of the EDF Algorithm:  \n",
            "A system T of independent, preemptab le tasks with relative deadlines equal to their respective \n",
            "periods can be feasibly scheduled on one processor if and only if its total utilization is equal to or \n",
            "less than 1.  \n",
            "When the relative deadlines of some tasks are less than their period, the system may not be \n",
            "feasible, even when its total utilization is less than 1.  \n",
            " \n",
            "For example : for task T1= (2,0.9),T2=(5, 2.3) is feasible but it would not be schedulable if its \n",
            "relative deadlines were 3 instead of 5.  \n",
            " \n",
            " \n",
            "Density:  \n",
            "The ratio of the execution time ek of a task Tk to the minimum of its relative deadline Dk and \n",
            "period pk the density δ k of the task.  \n",
            "In other words, the density of Tk is ek/min(Dk , pk). The sum of the densities of all tasks in a \n",
            "system is the density of the system and is denoted by ∆  when Di < pi for some task Ti , ∆ > U. If \n",
            "the density of a system is larger t han 1, the system may not be feasible. For example,\n",
            "23  \n",
            " \n",
            "ex.: T1=(2,0.9); T2=(5,2.3,3); Δ = 0.9/2+2.3/3 = 7.3/6 > 1, not feasible.  \n",
            "and the tasks are not schedulable by any algorithm. On the other hand, any system is feasible if \n",
            "its density is equal to or less than 1 . \n",
            "Theorem:  A system T of independent, preemptable, periodic tasks can be feasiblly scheduled in \n",
            "one processor if its den sity is less than or equal to 1 . \n",
            " \n",
            "The condition given by this theorem is not necessary for a system to be feasible. A system may \n",
            "nevertheless be feasible when its density is greater than 1. The system consisting  of (2, 0.6, 1) \n",
            "and (5, 2.3) is an example. Its density is larger than 1, but it is schedulable  according to the EDF \n",
            "algorithm.  \n",
            " \n",
            "A SCHEDULABILITY TEST FOR FIXED -PRIORITY TASKS  WITH SHORT \n",
            "RESPONSE TIMES : \n",
            "we consider  the case where the response times of the jobs are smaller than or equal to their \n",
            "respective periods. In other words, every job completes before the next job in the same task is \n",
            "released.  \n",
            " \n",
            "Critical Instant:  \n",
            "A critical  instant for a job is the worst -case release time for that job, taking into account all jobs \n",
            "that have higher priority  \n",
            "– i.e. a job released at the same instant as all jobs with higher priority are released, and must wait \n",
            "for all those jobs to complete bef ore it executes  \n",
            "– The response time of a job in Ti released at a critical instant is called the maximum (possible) \n",
            "response time, and is denoted by Wi  \n",
            " \n",
            "Example:\n",
            "24  \n",
            " \n",
            " \n",
            "3 tasks scheduled using rate -monotonic  \n",
            "• Response times of jobs in T2 are:  r2,1 = 0.8, r2,3 = 0.3, r2,3 = 0.2, r2,4 = 0.3, r2,5 = 0.8, …  \n",
            "Therefore critical instants of T2 are t = 0 and t = 10 \n",
            " \n",
            " \n",
            "THEOREM 6.5 In a fixed -priority system where every job completes before the next  job in the \n",
            "same task is released, a critical in  \n",
            "stant of any task Ti occu rs when one of  its job Ji,c is released at the same time with a job in \n",
            "every higher -priority task, that is,  ri,c = rk,lk for some lk for every k = 1, 2, . . . , i − 1. \n",
            "SCHEDULABILITY TEST FOR FIXED -PRIORITY TASKS  WITH ARBITRARY \n",
            "RESPONSE TIMES  \n",
            "This section describes a general time -demand analysis method developed by Lehoczky to \n",
            "determine the schedulability of tasks whose relative deadlines are larger than their respective \n",
            "periods. Since the response time of a task may be larger than its period, it may have m ore than \n",
            "one job ready for execution at any time. Ready jobs in the same task are usually scheduled on the \n",
            "FIFO basis. This policy is used here.  \n",
            " \n",
            " \n",
            "Busy Intervals\n",
            "25  \n",
            " \n",
            " \n",
            "Fig. illustrating Busy Intervals  \n",
            "A level -πi busy interval (t 0, t ] begins at an instant  t0 when (1) all jobs in Ti released before the \n",
            "instant have completed and (2) a job in Ti is released. The interval ends at the first instant t after \n",
            "t0 when all the jobs in Ti released since t0 are comp lete. In other words, in the interval (t0, t ], \n",
            "the processor is busy all the time executing  jobs with priorities πi or higher, all the jobs executed \n",
            "in the busy interval are released in the  interval, and at the end of the interval there is no backlog \n",
            "of jobs to be executed afterwards.  Hence, when computing the response times of jobs in Ti , we \n",
            "can consider every level -πi busy  interval independently from other level -πi busy intervals.  \n",
            " \n",
            "With a slight abuse of the term, we say that a level -πi busy interval is  in phase if the first  jobs of \n",
            "all tasks that have priorities equal to or higher than priority πi and are executed in this  interval \n",
            "have the same release time. Otherwise, we say that the tasks have arbitrary phases in  the interval.  \n",
            "As an example, Figure sh ows the schedule of three tasks T1 = (2, 1), T2 = (3, 1.25), and T3 = (5, \n",
            "0.25) in the first hyperperiod. The filled rectangles depict where jobs  in T1 are scheduled. The \n",
            "first busy intervals of all levels are in phase. The priorities of the  tasks are π1 = 1, π2 = 2, and π3 \n",
            "= 3, with 1 being the highest priority and 3 being the lowest  priority. As expected, every level -1 \n",
            "busy interval always ends 1 unit time after it begins. For  this system, all the level -2 busy\n",
            "26  \n",
            " \n",
            "intervals are in phase. They begin at times 0 , 6, and so on  which are the least common multiples \n",
            "of the periods of tasks T1 and T2. The lengths of these  intervals are all equal to 5.5. Before time \n",
            "5.5, there is at least one job of priority 1 or 2 ready  for execution, but immediately after 5.5, there \n",
            "are none. Hence at 5.5, the first job in T3 is scheduled. When this job completes at 5.75, the \n",
            "second job in T3 is scheduled. At time 6,  all the jobs released before time 6 are completed; \n",
            "hence, the first level -3 busy interval ends  at this time. The second  level -3 busy interval begins at \n",
            "time 6. This level -3 busy interval is  not in phase since the release times of the first higher -\n",
            "priority jobs in this interval are 6, but  the first job of T3 in this interval is not released until time \n",
            "10. The length of this  level -3 busy  interval is only 5.75. Similarly, all the subsequent level -3 \n",
            "busy intervals in the hyperperiod  have arbitrary phases.  \n",
            " \n",
            "General Schedulability Test  \n",
            "The general schedulability test described below relies on the fact that when determining the  \n",
            "schedulability of a task Ti in a system in which the response times of jobs can be larger than  their \n",
            "respective periods, it still suffices to confine our attention to the special case where the  tasks are \n",
            "in phase.  \n",
            " \n",
            "General Time -Demand Analysis Method  \n",
            "Test on e task at a time starting from the highest priority task T1 in order of decreasing  priority. \n",
            "For the purpose of determining whether a task Ti is schedulable, assume that  all the tasks are in \n",
            "phase and the first level -πi busy interval begins at time 0.\n",
            "27  \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " SCHEDULABILITY CONDITIONS FOR THE RM AND DM ALGORITHMS:  \n",
            "Consider case when the relative deadline of every task is equal to its  period. For such systems, \n",
            "the RM and DM algorithms are identical.  \n",
            " \n",
            "THEOREM 6.11. A system  of n independent, preemptable periodic tasks with relative  deadlines \n",
            "equal to their respective periods can be feasibly scheduled on a processor  according to the RM \n",
            "algorithm if its total utilization U is less than or equal to  URM(n) = n(21/n − 1) \n",
            " \n",
            "PRACTIC AL FACTORS: We have assumed that:  \n",
            "– Jobs are preemptable at any time.  \n",
            "– Jobs never suspend themselves.  \n",
            "– Each job has distinct priority.  \n",
            "– The scheduler is event driven and acts immediately.  \n",
            " These assumptions are often not valid… how does this affect the  system ?\n",
            "28  \n",
            " \n",
            "Blocking and Priority Inversion  \n",
            " \n",
            "• A ready job is blocked when it is prevented from executing by a  lower -priority job; a priority \n",
            "inversion is when a lower -priority  job executes while a higher -priority job is blocked . \n",
            "• These occur because some job s cannot be pre -empted:  \n",
            "– Many reasons why a job may have non -preemptable sections  \n",
            "• Critical section over a resource  \n",
            "• Some system calls are non -preemptable  \n",
            "• Disk scheduling  \n",
            "– If a job becomes non -preemptable, priority inversions may occur, these  may cau se a higher \n",
            "priority task to miss its deadline . \n",
            "– When attempting to determine if a task meets all of its deadlines, must  consider not only all the \n",
            "tasks that have higher priorities, but also nonpreemptable  regions of lower -priority tasks . \n",
            "• Add the blocki ng time in when calculating if a task is schedulable . \n",
            " \n",
            "Self-suspension  \n",
            "– A job may invoke an external operation (e.g. request an I/O operation),  during which time it is \n",
            "suspended . \n",
            "– This means the task is no longer strictly periodic… again need to take int o account self -\n",
            "suspension time when calculating a schedule . \n",
            "• Context Switches  \n",
            "– Assume maximum number of context switches Ki for a job in Ti is known;  each takes tCS time \n",
            "units . \n",
            "– Compensate by setting execution time of each job, eactual = e + 2tCS \n",
            "(more if jobs self -suspend, since additional context switches)  \n",
            " \n",
            "Tick Scheduling  \n",
            "• All of our previous discussion of priority -driven scheduling was  driven by job release and job \n",
            "completion events  \n",
            "• Alternatively, can perform priority -driven scheduling at periodic  events (timer interrupts) \n",
            "generated by a hardware clock  i.e. tick (or time -based) scheduling .\n",
            "29  \n",
            " \n",
            "• Additional factors to account for in schedulability analysis  \n",
            "– The fact that a job is ready to execute will not be noticed and acted upon  until the next clock \n",
            "interrupt; this will delay the completion of the job  \n",
            "– A ready job that is yet to be noticed by the scheduler must be held  somewhere other than the \n",
            "ready job queue, the pending job queue  \n",
            "– When the scheduler executes, it moves jobs in the pending queue to the ready queue according \n",
            "to their priorities; once in ready queue, the jobs  execute in priority order .\n",
            "30  \n",
            " \n",
            "Chapter -7 \n",
            "Scheduling aperiodic and sporadic jobs in priority driven systems : \n",
            " \n",
            "Assumptions and approaches -objectives : \n",
            "Assumptions:  \n",
            " The parameters of ea ch sporadic job become known after it is released.  \n",
            "  Sporadic jobs may arrive at any instant, even immediately after each other.  \n",
            "  Moreover, their execution times may vary widely, and  \n",
            " Their deadlines are arbitrary.  \n",
            "It is impossible for some sporadic jobs to meet their deadlines no matter what algorithm we use \n",
            "to schedule them. The only alternatives are : \n",
            " To reject the sporadic jobs that cannot complete in time or  \n",
            "  To accept all sporadic jobs and allow some of them to complete late. Which alternative \n",
            "is approp riate depends on the application.  \n",
            " \n",
            "Objectives, Correctness, and Optimality : \n",
            "We assume that we are given the parameters { pi } and { ei } of all the  periodic tasks and a \n",
            "priority -driven algorithm used to schedule them. Moreover, when the  periodic tasks are \n",
            "scheduled according to the given algorithm and there are no aperiodic and  sporadic jobs, the \n",
            "periodic tasks meet all their deadlines . \n",
            "We assume that the operating system maintains the priority  queues shown in following fig. The \n",
            "ready periodic jobs are placed  in the periodic task queue,  ordered by their priorities that are \n",
            "assigned according to the given periodic task scheduling  algorithm. Similarly, each accepted \n",
            "sporadic job is assigned a priority and is placed in a priority  queue, which may or may not be th e \n",
            "same as the periodic task queue. Each newly arrived  aperiodic job is placed in the aperiodic job \n",
            "queue. Moreover, aperiodic jobs are inserted in the  aperiodic job queue and newly arrived \n",
            "sporadic jobs are inserted into a waiting queue to await  acceptance  without the intervention of \n",
            "the scheduler.\n",
            "31  \n",
            " \n",
            " \n",
            "Fig. Priority queues maintained by Operating System  \n",
            " \n",
            "Aperiodic job and sporadic job scheduling algorithms; they are  solutions to the following \n",
            "problems:  \n",
            "1. Based on the execution time and deadline of each newly  arrived sporadic job, the scheduler  \n",
            "decides whether to accept or reject the job. If it accepts the job, it schedules the job  so that the \n",
            "job completes in time without causing periodic tasks and previously accepted  sporadic jobs to \n",
            "miss their deadlines. Th e problems are how to do the acceptance test  and how to schedule the \n",
            "accepted sporadic jobs.  \n",
            "2. The scheduler tries to complete each aperiodic job as soon as possible. The problem is  how to \n",
            "do so without causing periodic tasks and accepted sporadic jobs to  miss their  deadlines.  \n",
            " \n",
            "Such an algorithm is correct if it produces  only correct schedules of the system. By a correct \n",
            "schedule , we mean one according to which  periodic and accepted sporadic jobs never miss their \n",
            "deadlines .\n",
            "32  \n",
            " \n",
            "An aperiodic job scheduling algo rithm is optimal if it minimizes either  the response time of the \n",
            "aperiodic job at the head of the aperiodic job queue or the average  response time of all the \n",
            "aperiodic jobs for the given queueing discipline. An algorithm for  (accepting and) scheduling \n",
            "sporadic jobs is optimal if it accepts each sporadic job newly  offered to the system and schedules \n",
            "the job to complete in time if and only if the new job can  be correctly scheduled to complete in \n",
            "time by some means . \n",
            " \n",
            "Aperiodic job scheduling  \n",
            "• Background:  \n",
            "- Aperiodic job queue has always lowest priority among all queues.  \n",
            "- Periodic tasks (and accepted sporadic jobs) always meet deadlines.  \n",
            "- Simple to implement.  \n",
            "- Problem: execution of aperiodic jobs may be unduly delayed.  \n",
            "• Interrupt -Driven:  \n",
            "- Response time as short as possible.  \n",
            "- Periodic tasks may miss some deadlines.  \n",
            "• Slack -Stealing:  \n",
            "- Postpone execution of periodic tasks only when it is safe to do so:  \n",
            "• well -suited for clock -driven environments.  \n",
            "• what about priority -driven environments? (quite complicated) . \n",
            "• Polling Server:  \n",
            "- a periodic task that is scheduled with the other periodic tasks,  \n",
            "- executes the first job in the aperiodic job queue (when not empty . \n",
            "Polling Server  \n",
            " Polling Server (Poller) PS = (ps, es): scheduled as a periodic task, the polling  server takes care of \n",
            "executing aperiodic jobs when there are any waiting;  \n",
            "- ps: poller becomes ready for execution every ps time units,  \n",
            "- es: is the upper bound on execution time.  \n",
            "• Terminology:  \n",
            "- execution budget: es \n",
            "- size of the server: us = es / ps (it’s the maximum utilization factor of PS),\n",
            "33  \n",
            " \n",
            "- replenishment rule: the budget is set to es at the beginning of each period.  \n",
            "- consumption rules:  \n",
            " the poller consumes its budget at the rate of 1 per time unit, while it is  executing \n",
            "aperiodic jobs;  \n",
            " the poller  exhausts its budget whenever it finds the aperiodic  job queue empty;  \n",
            "- Whenever the budget is exhausted, the scheduler removes the poller from  the periodic queue \n",
            "until it is replenished;  \n",
            "- The server is idle when the aperiodic job queue is empy;  \n",
            "-The ser ver is backlogged when the aperiodic job queue is not empy.  \n",
            " \n",
            " \n",
            "Fig.Polling for T1 = (3, 1), T2 = (10, 4), poller = (2.5, 0.5) and A: r =0.1, e= 0.8  \n",
            "Descriptions of above fig.:  \n",
            "At the beginning of the first polling  period, the poller’s budget is replenished , but when  it \n",
            "executes, it finds the aperiodic job queue empty. Its execution budget is consumed \n",
            "instantaneously,  and its execution suspended immediately. The aperiodic job A arrives a short \n",
            "time later and must wait in the queue until the beginning of the second polling period when the  \n",
            "poller’s budget is replenished. The poller finds A at head of the queue at time 2.5 and executes  \n",
            "the job until its execution budget is exhausted at time 3.0. Job A remains in the aperiodic job\n",
            "34  \n",
            " \n",
            "queue and is again executed when  the execution budget of the poller is replenished at 5.0. The  \n",
            "job completes at time 5.3, with a response time of 5.2. Since the aperiodic job queue is empty  at \n",
            "5.3, the budget of the poller is exhausted and the poller suspends.  \n",
            " \n",
            "Bandwidth Preserving Serve rs \n",
            "Problem with polling servers:  \n",
            "-aperiodic jobs released after the poller has found the queue empty, must wait for the poller to \n",
            "examine the queue again, one polling period later: their response time is unduly longer;  \n",
            "-If the poller could preserve its bud get, when it finds the aperiodic job queue empy, and use it \n",
            "later in the period, the response time of some aperiodic jobs would be shortened.  \n",
            " \n",
            "• Bandwidth -preserving server algorithms:  \n",
            "In previous  example, if the poller were able to examine the queue again  at time 0.1, then job  A \n",
            "would complete in the second polling period, making its response time significantly shorter . \n",
            "Algorithms that improve the polling approach in this manner are called bandwidth preserving \n",
            "server  algorithms. Bandwidth -preserving server s are periodic servers. Each type  of server is \n",
            "defined by a set of consumption and replenishment  rules. The former give the  conditions under \n",
            "which its execution budget is preserved and consumed. The latter specify  when and by how \n",
            "much the budget is repleni shed.  \n",
            "i.e. \n",
            "- improve in this manner upon polling approach,  \n",
            "- use periodic servers,  \n",
            "- are defined by consumption and replenishment rules.  \n",
            "• 3 types of bandwidth -preserving server algorithms:  \n",
            " \n",
            " deferrable servers,  \n",
            " sporadic servers,  \n",
            " constant utilization / total bandwidth / weighted fair queuing - servers.  \n",
            " \n",
            "DEFERRABLE SERVERS  \n",
            "A deferrable server is the simplest of bandwidth -preserving servers. Like a poller, the execution\n",
            "35  \n",
            " \n",
            "budget of a defer rable server with period ps and execution budget es is replenished  periodically \n",
            "with period ps . Unlike a poller, however, when a deferrable server finds no aperiodic  job ready \n",
            "for execution, it preserves its budget.  However  Any budget held prior to replen ishment is lost (no \n",
            "carry -over).  \n",
            " \n",
            "Operations of Deferrable Servers  \n",
            "Specifically, the consumption and replenishment rules that define a deferrable server (ps , es) are \n",
            "as follows.  \n",
            "Consumption Rule  \n",
            "The execution budget of the server is consumed at the rate o f one per unit time whenever  the \n",
            "server executes.  \n",
            "Replenishment Rule  \n",
            "The execution budget of the server is set to es at time instants kpk, for k = 0, 1, 2, . . . .  \n",
            "Note that the server is not allowed to cumulate its budget from period to period. Stated  in another \n",
            "way, any budget held by the server immediately before each replenishment time is  lost. \n",
            "Suppose that the task  (2.5, 0.5) is a deferrable server. When it finds the aperiodic job queue \n",
            "empty at time 0, it  suspends itself, with its execution budget pre served. When aperiodic job A \n",
            "arrives at 0.1, the  deferrable server resumes and executes A. At time 0.6, its budget completely \n",
            "consumed, the  server is suspended. It executes again at time 2.5 when its budget is replenished. \n",
            "When A completes at time 2.8, the  aperiodic job queue becomes empty. The server is suspended, \n",
            "but it still has 0.2 unit of execution budget. If another aperiodic job arrives later, say at time 4.0,  \n",
            "the server resumes at that time.  \n",
            "Another example:  \n",
            "shows that the deferrable server TDS = (3, 1) has the highest priority. The periodic tasks T1 = \n",
            "(2.0, 3.5, 1.5) and T2 = (6.5, 0.5) and the server are scheduled rate -monotonically. Suppose that \n",
            "an aperiodic job A with execution  time 1.7 arrives at time 2.8.  \n",
            " \n",
            "1. At time 0, the server is given 1 un it of budget. The budget stays at 1 until time 2.8.When  \n",
            "A arrives, the deferrable server executes the job. Its budget decreases as it executes.  \n",
            "2. Immediately before the replenishment time 3.0, its budget is equal to 0.8. This 0.8 unit is  \n",
            "lost at time 3.0,  but the server acquires a new unit of budget. Hence, the server continues\n",
            "36  \n",
            " \n",
            "to execute.  \n",
            "3. At time 4.0, its budget is exhausted. The server is suspended, and the aperiodic job A waits.  \n",
            "4. At time 6.0, its budget replenished, the server resumes to execute A. \n",
            "5. At time 6.5, job A completes. The server still has 0.5 unit of budget. Since no aperiodic  job \n",
            "waits in the queue, the server suspends itself holding this budget.  \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Limitations of Deferrable Servers:  \n",
            "Limitation of deferrable servers – they may delay  lower -priority tasks for more time than a \n",
            "periodic  task with the same period and execution time:\n",
            "37  \n",
            " \n",
            " \n",
            "Sporadic Servers  \n",
            "• A sporadic server is designed to eliminate this  limitation . \n",
            "• A different type of bandwidth preserving server: several different subtypes  \n",
            "• More complex consumption and replenishment rules ensure that a  sporadic server with period \n",
            "ps and budget es never demands more  processor time than a periodic task with the same \n",
            "parameters . \n",
            " \n",
            "Simple Fixed -Priority Sporadic Server :  \n",
            "System, T, of independe nt preemptable periodic tasks and a sporadic server with parameters ( ps, \n",
            "es) \n",
            "• Fixed -priority scheduling; system can be scheduled if sporadic server  behaves as a periodic \n",
            "task with parameters ( ps, es) \n",
            "• Define:  \n",
            "• TH : the periodic tasks with higher priorit y than the server (may be empty)  \n",
            "• tr : the last time the server budget replenished  \n",
            "• tf : the first instant after tr at which the server begins to execute  \n",
            "• At any time t define:  \n",
            "• BEGIN as the start of the earliest busy interval in the most recent contig uous sequence of  busy \n",
            "intervals of TH starting before t (busy intervals are contiguous if the later one starts  immediately \n",
            "the earlier one ends)\n",
            "38  \n",
            " \n",
            "• END as the end of the latest busy interval in this sequence if this interval ends before t; define \n",
            "END = ∞ if  the interval ends after t. \n",
            " \n",
            "Consumption rule:  \n",
            "• At any time t ≥ tr, if the server has budget and if either of the following two  conditions is true, \n",
            "the budget is consumed at the rate of 1 per unit time:  \n",
            "• C1: The server is executing  \n",
            "• C2: The server has e xecuted since tr and END < t \n",
            "• When they are not true, the server holds its bud get. \n",
            "That is:  \n",
            "• The server executes for no more time than it has execution budget . \n",
            "• The server retains its budget if:  \n",
            "•  A higher -priority job is executing, or  \n",
            "•  It has not execut ed since t r. \n",
            "• Otherwise, the budget decreases when the server executes, or if it idles  while it has budget . \n",
            " \n",
            "Replenishment Rules:  \n",
            "• R1: When system begins executing, and each time budget is replenished, set the budget to \n",
            "es and tr = the current time.  \n",
            "• R2: Wh en server begins to execute (defined as time tf) \n",
            "if END = tf then \n",
            "te = max( tr, BEGIN )    //te is effective replenishment time  \n",
            "else if END < tf then \n",
            "te = tf \n",
            "The next replenishment time is set to te + ps \n",
            "• R3: budget replenished at the next replenishment time,  unless:  \n",
            "o If te + ps is earlier than tf the budget is replenished as soon as it is exhausted  \n",
            "•  If T becomes idle before te + p s, and becomes busy again at tb, the budget is replenished \n",
            "at min( tb, te + ps). \n",
            " \n",
            "Example: T1 = (3, 0.5) T2 = (4, 1.0) T3 = (19, 4. 5) TSS = (5, 1.5)\n",
            "39  \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Descriptions:  \n",
            "1. From time 0 to 3, the aperiodic job queue is empty and the server is suspended. Since it  \n",
            "has not executed, its budget stays at 1.5. At time 3, the aperiodic job A1 with execution  \n",
            "time 1.0 arrives; the server becomes read y. Since the higher -priority task (3, 0.5) has a  \n",
            "job ready for execution, the server and the aperiodic job wait . \n",
            "2. The server does not begin to execute until time 3.5. At the time, tr is 0, BEGIN is equal to \n",
            "3, and END is equal to 3.5. According to rule R2, the effective replenishment time te is \n",
            "equal to max  (0, 3.0) = 3, and the next replenishment time is set at 8.  \n",
            "3. The server executes until time 4; while it executes, its budget decreases with time .\n",
            "40  \n",
            " \n",
            "4. At time 4, the server is preempted by T2.While it is preempt ed, it holds on to its budget.  \n",
            "5. After the server resumes execution at 5, its budget is consumed until exhaustion because \n",
            "first it executes (C1) and then, when it is suspended again, T1 and T2 are idle (or  \n",
            "equivalently, END , which is 5.0, is less than the cu rrent time) (C2).  \n",
            "6. When the aperiodic job A2 arrives at time 7, the budget of the server is exhausted; the job \n",
            "waits in the queue.  \n",
            "7. At time 8, its budget replenished (R3), the server is ready for execution again.  \n",
            "8. At time 9.5, the server begins to execute fo r the first time since 8. te is equal to the latest \n",
            "replenishment time 8. Hence the next replenishment time is 13. The server executes until \n",
            "its budget is exhausted at 11; it is suspended and waits for the next replenishment time. In \n",
            "the meantime, A2 waits  in the queue.  \n",
            "9.  Its budget replenished at time 13, the server is again scheduled and begins to execute at \n",
            "time 13.5. This time, the next replenishment time is set at 18. However at 13.5, the \n",
            "periodic task system T becomes idle. Rather than 18, the budget i s replenished at 15, \n",
            "when a new busy interval of T begins, according to rule R3b.  \n",
            "10.  The behavior of the later segment also obeys the above stated rules. In particular, rule \n",
            "R3b allows the server budget to be replenished at 19.  \n",
            " \n",
            "CONSTANT UTILIZATION, TOTAL B ANDWIDTH, AND WEIGHTED \n",
            "FAIR -QUEUEING SERVERS  \n",
            "These three bandwidth preserving server algorithms that offer a simple way to  schedule \n",
            "aperiodic jobs in deadline -driven systems. They are constant utilization,  total bandwidth, and \n",
            "weighted fair -queueing algori thms. These algorithms belong  to a class of algorithms that more or \n",
            "less emulate the Gene ralized Processor Sharing (GPS) algorithm.  GPS, sometimes called fluid -\n",
            "flow processor sharing, is an idealized weighted round -robin  algorithm; it gives each backlogged  \n",
            "server in each round an infinitesmally small time  slice of length proportional to the server size.  \n",
            "Clearly, infinitesmally fine -grain time slicing cannot be implemented in practice  \n",
            " In particular, each server maintained and scheduled according to any of t hese algorithms offers  \n",
            "timing isolation to the task(s) executed by it; by this statement, we mean that the worst -case \n",
            "response times of jobs in the task are independent the processor -time demands of tasks  executed \n",
            "by other servers. While such a server work s in a way that is similar to sporadic  servers, its\n",
            "41  \n",
            " \n",
            "correctness relies on a different principle. The correctness of these algorithms follows from  the \n",
            "condition a schedulability condition of  sporadic jobs scheduled on the EDF . \n",
            " \n",
            "Schedulability of Sporadic Jo bs in Deadline -Driven Systems  \n",
            " \n",
            "The density of a sporadic job Ji that has release time ri , maximum execution time ei and \n",
            "deadline  di is the ratio ei /(di − ri ). A sporadic job is said to be active in its feasible interval (ri , \n",
            "di ]; it is not active outside of this interval. (Note : see on book for detail)  \n",
            " \n",
            "Theorem:  \n",
            "A system of independent, preemptable sporadic jobs is schedulable  according to the EDF \n",
            "algorithm if the total density of all active jobs in the system is no  greater than 1 at all times.  \n",
            " \n",
            "Corollary:  \n",
            "A system of n independent, preemptable sporadic tasks, which  is such that the relative deadline \n",
            "of every job is equal to its period, is schedulable o n a processor according to the EDF algorithm \n",
            "if the total instantaneous utilization (i.e  \n",
            " ), is equal to or less than 1.  \n",
            " \n",
            "COROLLARY:  \n",
            " A system of independent, preemptable , periodic and sporadic  tasks, which is such that the \n",
            "relative deadline of every job is equal to its period, is  schedulable on a processor according to the \n",
            "EDF algorithm if the sum of the total  utilization of the periodic tasks and the total instantaneous \n",
            "utilization of the sporadic  tasks is equal to or less than 1.  \n",
            "Constant Utilization se rver \n",
            "We now return our attention to the problem of scheduling aperiodic jobs amid periodic tasks  in a \n",
            "deadline -driven system. For the purpose of executing aperiodic jobs, there is a basic constant  \n",
            "utilization server . The server is defined by its size, whic h is its instantaneous utilization  ; this \n",
            "fraction of processor time is reserved for the execution of aperiodic jobs. As with  deferrable\n",
            "42  \n",
            " \n",
            "servers, the deadline d of a constant utilization server is always defined. It also  has an execution \n",
            "budget which is re plenished according to the replenishment rules described  below.  \n",
            "The server is eligible and ready for execution only when its budget is nonzero. When  the server \n",
            "is ready, it is scheduled with the periodic tasks on the EDF basis. While a sporadic  server \n",
            "emulates a periodic task, a constant utilization server emulates a sporadic task with a  constant \n",
            "instantaneous utilization, and hence its name . \n",
            " \n",
            "Consumption Rule : \n",
            "The consumption rule of a constant utilization  server, as well as that of a total bandwidth or \n",
            "weighted fair -queueing server, is quite  simple. A server consumes its budget only when it \n",
            "executes . \n",
            "Replinishment Rules:  \n",
            "us is the size of the server, es is its budget, and d is its deadline. t denotes the current time, and e \n",
            "denotes the execution time  of the job at the head the aperiodic job queue. The job at the head of \n",
            "the queue is removed  when it completes. The rules assume that the execution time e of each \n",
            "aperiodic job becomes  known when the job arrives.\n",
            "43\n",
            "44  \n",
            " \n",
            "TOTAL BANDWITH SERVER ALGORITHM  \n",
            " \n",
            "Example: same as the example of constant utilization server algorithm  \n",
            "SLACK STEALING IN DEADLINE DRIVEN SYSTEM  \n",
            "We know  that slack -stealing algorithms for deadline -driven systems are conceptu ally simpler \n",
            "than slack  stealing algorithms for fixed -priority syste ms. For this reason, we first focus on \n",
            "systems where periodic tasks are scheduled according to the EDF algorithm. In this part  \n",
            "aperiodic jobs are executed by a slack  stealer . The slack stealer is ready for execution whenever \n",
            "the aperiodic job queue is non empty and is suspended when the queue is empty. The scheduler \n",
            "monit ors the periodic tasks in order to keep track of the amount of available slack. It gives the \n",
            "slack stealer the highest priority whenever there is slack and the lowest priority whenever ther e is \n",
            "no slack. When the slack stealer executes, it executes the aperiodic job at the head of the  \n",
            "aperiodic job queue. This kind of slack -stealing algorithm is said to be greedy : The available \n",
            "slack is always used if there is an aperiodic job ready to be ex ecuted.  \n",
            "As an example, we consider  the system of two periodic tasks, T1 = (2.0, 3.5, 1.5) and T2 = (6.5, \n",
            "0.5). Suppose that in addition to  the aperiodic job that has execution time 1.7 and is released at \n",
            "2.8, another aperiodic job  with execution time 2.5 i s released at time 5.5. We call these jobs A1 \n",
            "and A2, respectively.  Figure 7 –15 shows the operation of a slack stealer.  \n",
            " \n",
            "1. Initially, the slack stealer is suspended because the ape riodic job queue is empty. When A1 \n",
            "arrives at 2.8, the slack stealer resume s. Because the exe cution of the last 0.7 units of J1,1 can be\n",
            "45  \n",
            " \n",
            "postponed until time 4.8 (i.e., 5 .5−0.7) and T2 has no ready job at the time, the system has 2 \n",
            "units of slack. The slack stealer is given the highest priority. It preempts  J1,1 and starts to \n",
            "execute A1. As it executes, the slack o f the system is consumed at the rate of 1 per unit time.  \n",
            "2. At time 4.5, A1 completes. The slack stealer is suspended. The job J1,1 resumes and executes \n",
            "to completion on time.  \n",
            "3. At time 5.5, A2 arrives, and the slack stealer becomes  ready again. At this time, the execution \n",
            "of the second job J1,2 of T1 can be postpo ned until time 7.5, and the second  job J2,2 of T2 can \n",
            "be postponed until 12.5. Hence, the sys tem as a whole has 2.0 units of slack. The slack stealer \n",
            "has the highest priority starting from this time. It executes A2. \n",
            "4. At time 7.5, all the slack consumed, the slack stealer is given the lowest priority. J1,2 \n",
            "preempts the slack stealer and starts to execute.  \n",
            "5. At time 9, J1,2 completes, and the system again has slack. The slack stealer now has the  \n",
            "highest priority. It continues to execute A2. \n",
            "6. When A2 comp letes, the slack stealer is suspended again. For as long as there is no job  \n",
            "in the aperiodic job queue, the periodic tasks execute on the EDF basis.  \n",
            " \n",
            "Fig Operation of stack stealer in deadline driven system\n",
            "46  \n",
            " \n",
            "SLACK STEALING IN FIXED -PRIORITY SYSTEMS  \n",
            "In pr inciple, slack stealing in a fixed -priority system works in  the same way as slack stealing in a \n",
            "deadline -driven system. However, both the computation  and the usage of the slack are more \n",
            "complicated in fixed -priority systems.  \n",
            "Optimality Criterion and Design  Consideration  \n",
            " The system contains three periodic tasks: T1 = (3, 1), T2 = (4, 1), and T3 = (6, 1). They are \n",
            "scheduled rate  monotonically. If the system were deadline -driven, it would have 2  units of slack \n",
            "in the interval (0, 3], but this system has only 1 unit. The reason is that once J1,2 becomes ready, \n",
            "J2,1 must wait for it to complete. As a consequence, J2,1 must complete b y time 3, although its \n",
            "deadline is 4. In essence, 3 is the effective deadline of J2,1, and its slack  is determined by the \n",
            "effective  deadline. Figure (a) shows the schedule for the case when the 1 unit of slack is not used \n",
            "before time 3. At time 3, J3,1 has already completed. J1,2 and J2,2 can start as late as time 5 and \n",
            "7, respectively, and still complete in time. Therefore, the syste m has two units of slack at time 3. \n",
            "Figure (b) shows the schedule for the other ca se: The 1 unit of slack is used before time 3. J3,1 is \n",
            "not yet complete at time 3. Consequently, J1,2 and J2,2 must execute immediately after they are \n",
            "released, even though t heir deadlines are 6 and 8; otherwise, J3,1 cannot complete in time. Under \n",
            "this condition, the system has no more slack until time 6.  \n",
            "This example points out the following important facts. The se facts provide the rationales for the \n",
            "slack -stealing algorithm  described below.  \n",
            "1. No slack -stealing algorithm can minimize the response  time of every aperiodic job in a \n",
            "fixed -priority system even when prior knowledge on the arrival times and execution times \n",
            "of aperiodic jobs are  available .  \n",
            "2.  The amount of slack a fixed -priority system has in a time interval may depend on when \n",
            "the slack is used. To minimize the response time of an aperiodic job, the decision on when \n",
            "to schedule the job must take into account the execution time of the job.\n",
            "47  \n",
            " \n",
            " \n",
            "Fig: Slack St ealing in fixed priority system  \n",
            " \n",
            "REAL -TIME PERFORMANCE FOR JOBS WITH SOFT TIMING CONSTRAINTS  \n",
            "For many applications, occasional missed deadlines are accep table; their sporadic jobs have soft \n",
            "deadlines by a sporadic job, we m ean one whose deadline is soft.\n",
            "48  \n",
            " \n",
            " Traffic Models  \n",
            " Each sporadic task is a stream of sporadic jobs that have the same inter -release time  and \n",
            "execution -time distributions and the same real -time performance requirements. The real-time \n",
            "performance experienced by each sporadic task is  typically measured in ter ms of such criteria as \n",
            "the maximum tardiness and miss rate of jobs in it. Once a sporadic task is admitted into the \n",
            "system, the scheduler accepts a nd schedules every job in it. Specifically, when requesting \n",
            "admission into the system,  each sporadic task pre sents to the scheduler its traffic parameters . \n",
            "These pa rameters define the constraints on the inter  arrival times and execution times of jobs in \n",
            "the task. The performance guarantee provided by the system to each task is conditional , meani ng \n",
            "that the system  delivers the guaranteed performance conditioned on the fact that the task m eets \n",
            "the constraints defined by its traffic parameters. Different traffic models use different traffic \n",
            "paramete rs to specify the behavior of a sporadic task.  \n",
            " FeVe and ( λ, β) Model s. According to the FeVe model, each  sporadic task is characterized by a \n",
            "4-tuple (e, p, p, I ) : e is the maximum executio n time of all jobs in the task; p is the minimum \n",
            "interarrival time of the jobs; p is their aver age interarrival time, and this average is taken over a \n",
            "time interval of length I .  The (λ, β) model, characterizes each sporadic task by a rate parameter \n",
            "λ and a  burst parameter β. The total execution time of all jobs that are r eleased in any time \n",
            "interval of length x is no more than β + λx. \n",
            "Leaky BucketModel. To define the leaky bucket mode l, we first introduce the notion of a (^, E) \n",
            "leaky bucket filter. Such a filter is specified by its (input) rate ^ and size E: The filter can hold at \n",
            "most E tokens at any time and it is being f illed with tokens at a constant rate of ^ tokens per unit \n",
            "time.  A token is lost if it arrives at the  filter when the filter already contains E tokens. We can \n",
            "think of a sporadic task that meets the (^, E) leaky bucket constraint as if its jobs were generated \n",
            "by the filter in the following manner.  \n",
            " \n",
            "A TWO -LEVEL SCHEME FOR INTEGRATED SCHEDULING  \n",
            "A two-level scheduling scheme that provides timing isolation to individual applications executed \n",
            "on one processor. Each ap plication contains an arbitrary number and types of tasks. By design, \n",
            "the two -level scheme a llows different applications to use different scheduling algorithms (e.g., \n",
            "some may be scheduled in a clock -driven manner while the others in a priority -driven manner). \n",
            "Hence, each application can be scheduled in a  way best for the application.\n",
            "49  \n",
            " \n",
            "Overview and Terminology  \n",
            "According to the two -level scheme, each application is execute d by a server. The scheduler at the \n",
            "lower level is called the OS scheduler . It replenishes the budget and sets the deadline of each \n",
            "server in the manners described below and schedules the ready servers on the EDF basis. At the \n",
            "higher level, each server has a server scheduler ; this scheduler schedules the jobs in the \n",
            "application executed by the server according to the algorithm chosen for the application.  \n",
            "Required Capability. In the description bel ow, we use Ti for i = 1, 2, . . . , n to denote n real \n",
            "time applications on a processor; each of thes e applications is executed by a server. To determine \n",
            "the schedulability and performance of each application Ti , we examine the tasks  in it as if the \n",
            "appli cation executes alone on a sl ower processor whose speed is a fraction s of the speed of the \n",
            "physical processor. In other w ords, we multiple the execution time of every job in the application \n",
            "by a factor 1 /s > 1 and use the product in place of the execution  time in the schedulability test on \n",
            "the application.  \n",
            "For example, the required capacity of an application t hat contains two periodic tasks (2, 0.5) and \n",
            "(5, 1) is 0.5 if it is scheduled rate -monotonically. The  reason is that we can multiple the \n",
            "execution ti me of each task by 2 and the resultant tasks (2, 1.0) and (5, 2) are schedulable, but if \n",
            "the multiplication factor were bigger, the resultant tasks would not be schedulable. If these tasks \n",
            "are scheduled on the EDF basis, its required capacity is 0.45.  \n",
            "Pred ictable versus Nonpredictable Applications.  In order to correctly maintain the server of \n",
            "an application that is sche duled according to a preemptive priority -driven algorithm, the OS \n",
            "scheduler needs an estimate of the occurrence time of every event of the application that may \n",
            "trigger a context switch with in the application. Such events include the releases and completions \n",
            "of jobs and their request s and releases of resources. At any time t , the next event of application \n",
            "Ti is the one that wou ld have the ear liest occurrence time after t among all events of Ti if the \n",
            "application were to ex ecute alone on a slow processor with speed si equal to its required \n",
            "capacity.  We call an application that is scheduled according  to a preemptive, priority -driven \n",
            "algorithm an d contains aper iodic and sporadic tasks and/or periodic tasks with release -time jitters \n",
            "an unpredictable application . The reason for this name is that the OS scheduler needs an \n",
            "estimate of its next event (occurre nce) time at each replenishment time of its server, but its server \n",
            "scheduler canno t compute an accurate estimate. All other types of applications are predictable .\n",
            "50  \n",
            " \n",
            " \n",
            "CHAPTER -8 \n",
            "RESOURCES AND RESOURCE ACCESS CONTROL  \n",
            " \n",
            "ASSUMPTIONS ON RESOURCES AND THEIR USAGE:  \n",
            " System contains only one processor  \n",
            "m contains ρ types of serially reusable  resources R1, R2 , … , Rρ. \n",
            "υi (υ = “upsilon”) indistinguishable  units of a resource of type Ri. \n",
            " \n",
            " \n",
            "n units . \n",
            " Serially reusable resources are allocated to jobs on a non-preemptive basis and used in a \n",
            "mutually exclusive manner  \n",
            " jobs at the same time, this is modeled as a  \n",
            "resource with several units, each used in a  mutual exclusive  manner . \n",
            " \n",
            "Enforcement of Mutual Exclusion  \n",
            " Mutual Exclusion is a lock -based concurrency control mechanism assumed to be used to \n",
            "enforce mutual exclusive access to resources.  \n",
            " when a job wants to use υi units of a resource Ri, it executes a lock L (Ri, ηi) (η = “eta”) to \n",
            "request them . \n",
            " When the job no longer needs the resources,  it releases them be executing an unlock \n",
            "U(Ri,ηi). \n",
            " When a lock request fails, the requesting job  is blocked and loses the processor  \n",
            "  It stays blocked until the scheduler grants the  resou rces the job is waiting for . \n",
            "  If a resource has only 1 unit the simpler  notations L(Ri) and U(Ri) are used for lock  and \n",
            "unlock  resp.\n",
            "51  \n",
            " \n",
            "Critical Section  \n",
            " \n",
            " A segment of a job that begins with a lock and ends at a matching unlock is called a \n",
            "critical sectio n. \n",
            "  Resources are released in last -in-first-out order . \n",
            "  A critical section that is not included in other  critical sections is called an outermost \n",
            "critical  section . \n",
            "  Critical sections are denoted by [ R, η; e], where R gives the name and η the number of  \n",
            "units of a resource and e the (maximum)  execution time of the critical section . \n",
            "  If there is only one unit of a resource the  simpler notation [ R; e] is used . \n",
            " \n",
            " \n",
            "Fig. Example of Critical Section  \n",
            " \n",
            " \n",
            "As an exam ple, above fig shows three jobs, J1, J2, and J3, and the time instants when  locks and \n",
            "unlocks are executed if each job executes alone starting from time 0. Resources R1, R2, and R3 \n",
            "have only 1 unit each, while resources R4 and R5 have many units. Job J3 has three  overlapping \n",
            "critical sections that are properly nested. A critical section that is not included in  other critical \n",
            "sections is an outermost critical section ; the critical section delimited by L(R1) and U(R1) in J3 \n",
            "is an example. Other examples are t he critical sections delimited by L (R2) and U(R2) in J2, the \n",
            "second pair of L(R3) and U(R3) in J2 and L(R3) and U(R3) in J1. the critical section in J3 that \n",
            "begins at L(R5, 4) is [R5, 4; 3]  because in this critical section, the job uses 4 units of R5 and the \n",
            "execution time of this critical  section is 3.\n",
            "52  \n",
            " \n",
            "Resource Conflicts  \n",
            " Two jobs conflict with each other, if some of the  resources they require are of the same \n",
            "type. \n",
            "  They contend for a resource when one job requests  a resource that the other job alread y \n",
            "has. \n",
            "  These terms are used interchangeably . \n",
            "J1, J2, and J3 with feasible intervals (6,14], (2,  17], (0,18]  \n",
            "R; 2], [ R; 4], [ R; 4] for jobs 1, 2, 3  \n",
            "-schedule . \n",
            " \n",
            "Priority Inversion : \n",
            "Priority inversion occurs, when a low -priority job  executes while a ready higher -priority job \n",
            "waits .\n",
            "53  \n",
            " \n",
            " \n",
            "Timing Anomalies  \n",
            " \n",
            "R; 2.5] instead of [ R; 4] \n",
            " \n",
            "Resource Conflicts : \n",
            "In this example J1 is blocked by J3  But J3 is preempted by J2  Thus J1 has to wait for the \n",
            "lower -priority job J2 that does not  even require the resource that J1 needs In this case priority \n",
            "inversion is considered uncontrolled .\n",
            "54  \n",
            " \n",
            " \n",
            "Need for Protocols ? \n",
            "Protocols are needed to  handle priority  inversion in a controlled way and to avoid  deadlock . \n",
            "Deadlock : \n",
            "Deadlock can occur, if jobs block each other from  execution .\n",
            "55  \n",
            " \n",
            "Wait -for-Graphs  \n",
            "-for-Graphs are used to describe the dynamic -blocking relationship among jobs  \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "-for-graph indicates a de adlock.  \n",
            "In the example:  \n",
            " \n",
            " \n",
            " \n",
            ". \n",
            " \n",
            " \n",
            "The following system is de adlocked :\n",
            "56  \n",
            " \n",
            " \n",
            " \n",
            "Non-preemptive Critical  Sections Protocol (NPCS) : \n",
            " Simplest resource access control protocol .  \n",
            " All critical sections are scheduled nonpreemptively .\n",
            "57  \n",
            " \n",
            "Advantages:  \n",
            " Simple to implement  \n",
            "  Uncontrolled priority inversion cannot occur  \n",
            "  A high -priori ty job can only be blocked once  because of a low -priority job  \n",
            " Good protocol when critical sections are short  \n",
            " : \n",
            " \n",
            "Disadvantages : \n",
            "-priority  job even if there is no resource conflict \n",
            "between  them . \n",
            " \n",
            "Priority Inheritance Protocol:  \n",
            " Works with any priority -driven scheduling algorith m. \n",
            "  Uncontrolled priority inversion cannot occur.  \n",
            "  Protocol does not avoid deadlock.  \n",
            " External mechanisms needed to avoid deadlock . \n",
            " \n",
            "Assumption:  \n",
            ". \n",
            " Definitions:  \n",
            "is its assigned priority\n",
            "58  \n",
            " \n",
            "t, each ready job Jl is scheduled and executes at its current priority π l(t), which \n",
            "may differ from its assigned priority and vary with time.  \n",
            "Priority Inheritance  \n",
            "The current priority πl(t) of a job Jl may be raised  to the higher priority πh(t) of a job Jh \n",
            "-priority job Jl inherits the priority of higher -priority \n",
            "job Jh, and that Jl executes at its inherited priority π h(t) \n",
            "Scheduling Rule  \n",
            "cessor  preemptively in a priority -driven manner according  \n",
            "to their current priorities.  \n",
            "t, the current priority π(t) of every job J is equal to its assigned priority  \n",
            " condition stated in the priority -inheritance \n",
            "rule. \n",
            "Allocation Rule  \n",
            "J requests a resource R at time t, \n",
            "a) if R is free, R is allocated to J until J releases the  resource, and  \n",
            "b) if R is not free, the request is denied and J is blocked . \n",
            "Priority -Inheritance Rule : \n",
            "J becomes blocked, the  job Jl which blocks J inherits the current \n",
            "priority  π(t) of J. \n",
            "Jl executes at its inherited priority π(t) until it releases R. \n",
            "Jl returns to its priority  πl(t’) at the time t’ when it acquired the \n",
            "resource  R.\n",
            "59  \n",
            " \n",
            "Example:  \n",
            " \n",
            "Description:  \n",
            " When J1 requests resource R and becomes blocked at time 3, job J3 inherits the priority \n",
            "π1 of job J1. \n",
            "  When J2 becomes ready at time 5, it cannot preempt J3 because its priority π2 is lower \n",
            "than the inherited priority π1 of J3. \n",
            "  As a consequence J3 completes its critical section as soon as  possible . \n",
            " \n",
            "Next Example:\n",
            "60  \n",
            " \n",
            " \n",
            " \n",
            "Description:  \n",
            "1.At time 0, job J5 becomes ready and executes at its assigned priority 5. At time 1, it is  \n",
            "granted the resou rce Black . \n",
            "2. At time 2, J4 is released. It preempts J5 and starts to execute.  \n",
            "3. At time 3, J4 requests Shaded . Shaded , being free, is granted to the job. The job continues  to \n",
            "execute.\n",
            "61  \n",
            " \n",
            "4. At time 4, J3 is released and preempts J4. At time 5, J2 is release d and preempts J3. \n",
            "5. At time 6, J2 executes L(Black) to request Black ; L(Black) fails because Black is in use  by J5. \n",
            "J2 is now directly blocked by J5. According to rule 3, J5 inherits the priority 2 of  J2. Because \n",
            "J5’s priority is now the highest among al l ready jobs, J5 starts to execute.  \n",
            "6. J1 is released at time 7. Having the highest priority 1, it preempts J5 and starts to execute.  \n",
            "7. At time 8, J1 executes L(Shaded) , which fails, and becomes blocked. Since J4 has  Shaded at \n",
            "the time, it directly blocks  J1 and, consequently, inherits J1’s priority 1. J4 now has the highest \n",
            "priority among the ready jobs J3, J4, and J5. Therefore, it starts to  execute.  \n",
            "8. At time 9, J4 requests the resource Black and becomes directly blocked by J5. At this  time the \n",
            "current  priority of J4 is 1, the priority it has inherited from J1 since time 8.  Therefore, J5 inherits \n",
            "priority 1 and begins to execute.  \n",
            "9. At time 11, J5 releases the resource Black . Its priority returns to 5, which was its priority  when \n",
            "it acquired Black . The job with the highest priority among all unblocked jobs is  J4. \n",
            "Consequently, J4 enters its inner critical section and proceeds to complete this and  the outer \n",
            "critical section.  \n",
            "10. At time 13, J4 releases Shaded . The job no longer holds any resource; its pri ority returns  to 4, \n",
            "its assigned priority. J1 becomes unblocked, acquires Shaded , and begins to  execute.  \n",
            "11. At time 15, J1 completes. J2 is granted the resource Black and is now the job with the  highest \n",
            "priority. Consequently, it begins to execute.  \n",
            "12. At time 17, J2 completes. Afterwards, jobs J3, J4, and J5 execute in turn to completion.  \n",
            " \n",
            "Basic Priority Ceiling Protocol  \n",
            " Definitions  \n",
            "priority ceiling of any resource Ri is the  highest priority of all jobs that require R and is  \n",
            "denoted Π( Ri).\n",
            "62  \n",
            " \n",
            "t, the current priority ceiling ΠC(t) of the system is   equal to the highest priority \n",
            "ceiling of the resources  that are in use at the time, if some resources are in  use. \n",
            "-existing priority that is lower  than the priority of any job . \n",
            "Basic Priority -Ceiling Protocol : \n",
            "Scheduling Rule  \n",
            "As its release time t, the current priority π(t) of each job J is equal t o its assigned priority.  \n",
            "Priority -Inheritance \n",
            "rule. \n",
            "J is scheduled preemptively and in a priority -driven manner at its current priority \n",
            "π(t). \n",
            "Allocation Rule : \n",
            "job J requests a resource R at time t, \n",
            "a) R is held by another job, the request is denied and J is blocked . \n",
            "b) R is free  \n",
            "i.  If J’s current priority π(t) is higher than the current priority  ceiling of the system \n",
            "ΠC(t), R is allocated to J \n",
            "ii. If J’s curren t priority π(t) is not higher than the current  ceiling of the system Π C (t), R \n",
            "is allocated to J only if J is the  job holding the resource(s) whose priority ceiling is equal  to \n",
            "ΠC(t); otherwise J’s request is denied and J becomes  blocked . \n",
            "Priority -Inherita nce Rule : \n",
            "J becomes blocked, the job Jl which  blocks J inherits the current priority π(t) of J. \n",
            "Jl executes at its inherited priority π(t) until the  time where it releases every resource whose  \n",
            "priority ceiling is equal to or higher than π(t).\n",
            "63  \n",
            " \n",
            " that time, the priority of Jl returns to its priority  πl(t’) at the time t’ when it was granted the  \n",
            "resource(s) . \n",
            "Eample:  \n",
            " \n",
            "Description:(see book page no 291 for description).  \n",
            " \n",
            "Stack Sharing:  \n",
            " Sharing of the stack among jobs eliminates stack space fragmenta tion and allows for \n",
            "memory savings:  \n",
            " with no stack sharing, each single job needs some private  memory space to allow for its \n",
            "stack growing;  \n",
            "  with stack sharing, there is just one single memory space for  all stacks growing .\n",
            "64  \n",
            " \n",
            " \n",
            " \n",
            "when a job J executes, its stac k frame is on top of the stack;  \n",
            "• The stack frame is freed when J completes;  \n",
            "• When J is preempted, the preempting job has its stack frame  on top of J’s frame;  \n",
            "•Iin a stack sharing system, a job J may resume only when all  jobs holding stack space above its  \n",
            "frame have completed and  leave J’s frame on top of the stack again ; \n",
            "• In a stack sharing system, a job J must never self -suspend  \n",
            "- in case this happened, no other previously active, lower  priority job JL could proceed, \n",
            "since its stack space would not  be on top of the stack: only higher priority jobs could  \n",
            "(preempt) and execute; J would keep the processor busy (at  its own priority level) while \n",
            "self-suspended, which is the  same as saying that in a stack sharing system jobs cannot  \n",
            "self-suspend.  \n",
            " In a stack sha ring system, after a job J has begun execution, it  must never be blocked \n",
            "because it is denied some resource  assigned to a lower priority job JL: \n",
            "- in case this happened, J could proceed only after the  (previously active, lower \n",
            "priority) blocking job JL has been resumed and has freed the requested resource;\n",
            "65  \n",
            " \n",
            "but this would not be possible, because the stack space of  this (previously active, \n",
            "lower priority) blocking job JL would  not be on top of the stack;  \n",
            "⇨ this would cause deadlock ( J needs R held by JL; JL needs the stack held by J); \n",
            " \n",
            "In a stack sharing system  (assumptions):  \n",
            "- jobs may be preempted (by higher priority jobs),  \n",
            "- must never blocked (by lower priority jobs),  \n",
            "- must never self -suspend . \n",
            "Stack B ased Priority -Ceiling Protocol:  \n",
            "Based on the stack sharing principle (for non self -suspending jobs).  \n",
            "• To avoid deadlocks: the protocol makes sure that once a job begins  execution, it will not be \n",
            "blocked due to resource access.  \n",
            "• Define: Π (t) = highest pr iority ceiling of all resources allocated at t. if no resource is allocated, \n",
            "Π (t) = Ω. \n",
            "SBPC protocol : \n",
            "1. Update Priority Ceiling: whenever all resources are free, Π (t) = Ω.  The value of Π (t) is \n",
            "updated whenever a resource is allocated or freed.  \n",
            "2.  Sche duling Rule: after a job is released, it is blocked from starting  execution until its assigned \n",
            "priority is higher than Π (t). Jobs that are not blocked are scheduled on the processor in a priority  \n",
            "driven,  preemptive fashion according to their assigned prio rities.  \n",
            "3. Allocation Rule: whenever a job requests a resource, it is allocated the  resource.\n",
            "66  \n",
            " \n",
            "Example: All the parameters of jobs are same of above example except let J2 be released at 4.8 \n",
            "and the execution time of the critical section of J2 be 1.2. The sch edule is as follows.  \n",
            " \n",
            "Fig:SBPC  \n",
            "USE OF PRIORITY -CEILING PROTOCOL IN DYNAMIC -PRIORITY SYSTEMS  \n",
            " \n",
            "While both versions of the priority -ceiling protocol are rel atively simple to implement and \n",
            "perform well when periodic tasks are scheduled on a fixed -prior ity bas is, it is another matter in a \n",
            "dynamic -priority system. In a dynamic -priority system, the prior ities of the periodic tasks change \n",
            "with time while the resources required by each task rem ain constant. As a consequence, the \n",
            "priority ceilings of the resources m ay change with time.  \n",
            "As an example, let us look at the EDF schedule of two tasks T1 = (2, 0.9) and T2 = (5, 2.3) in \n",
            "Figure 6 –4. In its first two periods (i.e., from time 0 to 4), T1 has priority 1 while  T2 has priority \n",
            "2, but from time 4 to 5, T2 has prior ity 1 and T1 has priority 2. Suppose that the  task T1 requires \n",
            "a resource X while T2 does not. The priority ceiling of X is 1 from time 0 to  4 and becomes 2 \n",
            "from time 4 to 5, and so on.   \n",
            "Implementation of  Priority -Ceiling Protocol in Dynamic -Priority Syste ms\n",
            "67  \n",
            " \n",
            "One way to implement the basic priority -ceiling protocol in a job-level fixed -priority system is to \n",
            "update the priority ceilings of all resources whenever a new  job is released. Specifically, when a \n",
            "new job is released, its priority relative to all the jobs in the ready queue is assigned according to \n",
            "the given dynamic -priority algorithm. Then, the priorit y ceilings of all the resources are updated \n",
            "based on the new priorities of the tasks, a nd the ceiling of the system is updated based on the \n",
            "new priority  ceilings of the resources. The  new priority ceilings are used until they are updated \n",
            "again upon the next job release.  The example in Figure 8 –18 illustrates the use of this  protocol in \n",
            "an EDF system. The system shown here has three tasks: T1 = (0.5, 2.0, 0.2; [Black ; 0.2]), T2 = \n",
            "(3.0, 1.5; [Shaded ; 0.7]), and T1 = (5.0, 1.2; [Black ; 1.0 [ Shaded ; 0.4]). The priority ceilings of \n",
            "the two resources Black and Shaded are updated at times 0, 0.5, 2.5, 3, 4.5, 5, 6, and so on.  \n",
            "1.  At time 0, there are only two ready jobs, J2,1 and J3,1. J2,1 (and hence T2) has priority  \n",
            "1 while T3 has priority 2, the priority of J3,1. The priority ceilings of Black and Shaded  \n",
            "are 2 and 1, respectively. Since J2,1 has a higher priority, it begins to execute. Because  \n",
            "no resource is in us e, the ceiling of the system is . At time 0.3, J2,1 acquires Shaded , and \n",
            "the ceiling of the system rises from  to 1, the priority ceiling of Shaded . \n",
            "2. At time 0.5, J1,1 is released, and it has a higher priority than J2,1 and J3,1. Now the  \n",
            "priorities of T1, T2, and T3 become 1, 2, and 3, respectively. The priority ceiling ( Black ) \n",
            "of Black is 1, the priority of J1,1 and T1. The priority ceiling _t (Shaded ) of Shaded \n",
            "becomes 2 because the priority of J2,1 and T2 is now 2. The ceiling of the  system based \n",
            "on these  updated values is 2. For this reason, J1,1 is granted the resource  Black . The \n",
            "ceiling of the system is 1 until J1,1 releases Black and completes at time 0.7.  Afterwards, \n",
            "J2,1 continues to execute, and the ceiling of the system is again 2. When  J2,1 comple tes \n",
            "at time 1.7, J3,1 commences to execute and later acquires the resources  as shown.  \n",
            "3. At time 2.5, J1,2 is released. It has priority 1, while J3,1 has priority 2. This update of  \n",
            "task priorities leads to no change in priority ceilings of the resources. Sinc e the ceiling  of \n",
            "the system is at 1, J1,2 becomes blocked at 2.5. At time 2.9, J3,1 releases Black , and  J1,2 \n",
            "commences execution.  \n",
            "4. At time 3.0, only T1 and T2 have jobs ready for execution. Their priorities are 1 and 2,  \n",
            "respectively. The priority ceilings o f the resources remain unchanged until time 4.5.  \n",
            "5. At time 4.5, the new job J1,3 of T1 has a later deadline than J2,2. (Again, T3 has no \n",
            "ready  job.) Hence, the priority of T1 is 2 while the priority of T2 becomes 1. This change\n",
            "68  \n",
            " \n",
            "in task priorities causes the priority ceilings of Black and Shaded to change to 2 and 1,  \n",
            "respectively.  \n",
            "6.  At time 5 when J3,2 is released, it is the only job ready for execution at the time and  \n",
            "hence has the highest priority. The priority ceilings of both reso urces are 1. These values  \n",
            "remain until time 6.  \n",
            " \n",
            "CONTROLLING ACCESSES TO MULTIPLE -UNIT RESOURCES  \n",
            "Both versions of the priority -ceiling protocol and preemption -ceiling p rotocol described in  the \n",
            "previous sections assume that there is only one unit of each resource. We now describe an  \n",
            "extension to these protocols so that they can deal with the general case where there may be  more \n",
            "than one unit of each resource (type).  \n",
            " Priority (Preemption) Ceilings ofMultiple -Unit Resources  \n",
            "The first step in extending the priority -ceiling protocol is to modify the definition of the priority  \n",
            "ceilings of resources. We let _(Ri , k), for k ≤ vi , denote the priority ceiling of a resource  Ri \n",
            "when k out of the νi (≥ 1) units of Ri are free. If one or more jobs in the system require  more than \n",
            "k units of Ri , _(Ri , k) is the highest priority of all these jobs. If no job requires  more than k units \n",
            "of Ri , _(Ri , k) is equal to , the nonexistin g lowest priority. In this notation,  the priority ceiling  \n",
            "_(Rj ) of a resource Rj that has only 1 unit is _(Rj , 0). \n",
            " \n",
            "CONTROLLING CONCURRENT ACCESSES TO DATA OBJECTS\n",
            "69  \n",
            " \n",
            "Data objects are a special type of shared resources. When jobs are scheduled preemptively,  their \n",
            "accesses to (i.e., reads and writes) data objects may be interle aved. To ensure data integrity,  it is \n",
            "common to require that the reads and writes be se rializable. A sequence of reads  and writes by a  \n",
            "set of jobs is serializable if the effect produced by the sequence on all the data  objects shared by  \n",
            "the jobs is the same as the effect produced by a serial sequence (i.e ., the  sequence of reads and  \n",
            "writes when the jobs execute according to a nonpreemptive schedule).  \n",
            "Convex -Ceiling Protocol  \n",
            "The reso urce access -control protocols described in earlier sections  do not ensure serializability.  \n",
            "For example, both the NPCS and PC (Priority - and Pree mption -Ceiling) protocols allow  a \n",
            "higher -priority job Jh to read and write a data object X between two disjoint critical sections  of a \n",
            "lower -priority job Jl during which Jl also reads and writes X. The value of X thus produced may  \n",
            "not be the same as the value produced by ei ther of the two possible serial  sequences (i.e., all the  \n",
            "reads and writes of Jl either proceed or follow that of Jh ). \n",
            "Motivation and Assumptions. A well -known way to  ensure serializab ility is Two - Phase \n",
            "Locking (2PL). According to the 2PL protocol, a job never requests any lock once it  releases \n",
            "some lock.  We ca n easily get concurrency -control protocols that not only ensure serializability \n",
            "but also prevent deadlock and transitive blocking by augmenting the  protocols . As a result, we  \n",
            "have the NPCS -2PL and the PCP - 2PL protocols.  \n",
            "Priority -Ceiling Function. As with the PCP -2PL protoc ol, the convex -ceiling protocol  assumes \n",
            "that the scheduler knows a priori the data obje cts require by each job and,  therefore, the priority  \n",
            "ceiling of each data object. In addition, each job notifies the scheduler  immediately after it \n",
            "accesses each of its required objects for the last time. We call a notification  sent by a job Ji after \n",
            "it accesses Rk for the last time the last access notification for Rk by Ji and the time of this \n",
            "notification the last access time of R k by Ji. For example  the job Ji requires three data objects: \n",
            "Dotted , Black , and Shaded . Their priority ceilings are 1, 2, and 3, respectively. Figure 8 -23(a) \n",
            "shows the time intervals  when the job executes and accesses the objects. The two functions of \n",
            "the job are shown  in Figur e. At time 0, RP(Ji , 0) is 1. The job sends las t access notifications at \n",
            "times  4, 6, and 8 when it no longer needs Dotted , Black , and Shaded , respectively. The scheduler  \n",
            "updates RP(Ji , t) at these instants; each time, it low ers the re mainder priority ceiling to the  \n",
            "highest priority ceiling of all objects still required by the job in the future.\n",
            "70\n"
          ]
        }
      ],
      "source": [
        "# import re\n",
        "\n",
        "# cleaned_pages = []\n",
        "\n",
        "# for page in pages:\n",
        "#     # Assuming each page has an attribute 'page_content' that holds the text\n",
        "#     cleaned_content = re.sub(r'[\\uD800-\\uDFFF]', '', page.page_content)\n",
        "#     cleaned_pages.append(cleaned_content)  # Store the cleaned content in a new list\n",
        "\n",
        "# # Now you can use 'cleaned_pages' which is alist of cleaned page contents\n",
        "# for cleaned_content in cleaned_pages:\n",
        "#     print(cleaned_content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tl5Z9r5hVHPc",
        "outputId": "82f2ac47-f1d6-42db-ce36-ff3033d6ea80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#type(cleaned_pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zbUBrQNzRwM",
        "outputId": "ba249fe4-9c39-436a-a446-813260891bf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The total words in the context:  153785\n"
          ]
        }
      ],
      "source": [
        "context = \"\\n\".join(str(p.page_content) for p in pages)\n",
        "#context = \"\\n\".join(cleaned_pages[:100])\n",
        "print(\"The total words in the context: \", len(context))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjP8CpfWfC2c"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SJ_gRA63F10"
      },
      "outputs": [],
      "source": [
        "prompt_template = \"\"\"Answer the question as precise as possible using the provided context. If the answer is\n",
        "                    not contained in the context, say \"answer not available in context\" \\n\\n\n",
        "                    Context: \\n {context}?\\n\n",
        "                    Question: \\n {question} \\n\n",
        "                    Answer:\n",
        "                  \"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdTF4tp83K0t"
      },
      "outputs": [],
      "source": [
        "stuff_chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWQkrsfV3N0p"
      },
      "outputs": [],
      "source": [
        "question = \"Why data management is Important??\"\n",
        "\n",
        "\n",
        "stuff_answer = stuff_chain(\n",
        "    {\"input_documents\": pages[:10], \"question\": question}, return_only_outputs=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoAH55Hp3TsO",
        "outputId": "c873dbdd-83a9-4e89-a7ec-66ae8bb1687d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'output_text': 'Real-time systems are defined as those systems in which the '\n",
            "                'correctness of the system depends not only on the logical '\n",
            "                'result of the computation, but also on the time at which the '\n",
            "                'results are produced.'}\n"
          ]
        }
      ],
      "source": [
        "pprint(stuff_answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2N4Tk2Ol3Xj3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4LJ0OTyfEfr"
      },
      "source": [
        "LLAMA INDEX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWnqeMlMfGxU",
        "outputId": "0d54f43a-f4b1-4728-eab1-640281bb2d6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.10/dist-packages (0.9.21)\n",
            "Requirement already satisfied: google-generativeai>=0.3.0 in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: qdrant_client in /usr/local/lib/python3.10/dist-packages (1.7.0)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from llama-index) (4.12.2)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.6.3)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.2.14)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.26.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.8)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.23.5)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.5.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (4.9.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.9.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.4.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai>=0.3.0) (0.4.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from google-generativeai>=0.3.0) (2.17.3)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai>=0.3.0) (2.11.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai>=0.3.0) (4.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai>=0.3.0) (4.66.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.4.0->google-generativeai>=0.3.0) (1.23.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (1.60.0)\n",
            "Requirement already satisfied: grpcio-tools>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (1.60.0)\n",
            "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (2.8.2)\n",
            "Requirement already satisfied: pydantic>=1.10.8 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (1.10.13)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.26.14 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (1.26.18)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.2->llama-index) (2.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama-index) (1.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant_client) (67.7.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index) (1.0.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index) (1.3.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index) (4.1.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (2023.6.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index) (1.7.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index) (3.0.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index) (3.20.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai>=0.3.0) (1.62.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai>=0.3.0) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai>=0.3.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai>=0.3.0) (4.9)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2023.3.post1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index) (1.2.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai>=0.3.0) (1.48.2)\n",
            "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx->llama-index) (6.0.1)\n",
            "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx->llama-index) (4.0.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai>=0.3.0) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index 'google-generativeai>=0.3.0' matplotlib qdrant_client\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCX7_uGpfQQE"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms import Gemini\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCtg5xZ_fphI"
      },
      "outputs": [],
      "source": [
        "GOOGLE_API_KEY= 'AIzaSyBhah77AspnXGB_1JgodpJog4ShEXCgZbo'\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWfJAapkhgNF"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms import Gemini\n",
        "\n",
        "#resp = Gemini().complete(\"Write a poem about a magic backpack\")\n",
        "#print(resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WBHVD7tNjcrG",
        "outputId": "74f2669b-9c24-44f7-a90e-49c0643862d6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "wZCyEDrVinT2"
      },
      "outputs": [],
      "source": [
        "from llama_index import SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader(\n",
        "    \"/content\"\n",
        ").load_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mw_TmPU_kw9N",
        "outputId": "c04cc052-5e3a-4808-cee5-5bf5b67c3b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> \n",
            "\n",
            "83 \n",
            "\n",
            "<class 'llama_index.schema.Document'>\n",
            "Doc ID: 88ef8e9c-e9df-4b84-b217-82265d543c8b\n",
            "Text: ----------------------------------------------------------------\n",
            "-------------------------------------------------------------\n",
            "-------------   By Bhupendra Singh Saud  ADBMS   1\n",
            "Course of Contain   Unit 1: The Relational Model of Data and RDBMS\n",
            "Implementation Techniques [5 Hrs.]   Theoretical concepts, Relational\n",
            "model conformity an...\n"
          ]
        }
      ],
      "source": [
        "print(type(documents), \"\\n\")\n",
        "print(len(documents), \"\\n\")\n",
        "print(type(documents[0]))\n",
        "print(documents[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "aArkfOe6k4QO"
      },
      "outputs": [],
      "source": [
        "from llama_index import Document\n",
        "\n",
        "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jd2eUvgTlTNm",
        "outputId": "28ba9da1-6fdc-4196-fed6-4b0beda4b9cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "llama_index.schema.Document"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "type(document)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "5fCyUgj8lMww"
      },
      "outputs": [],
      "source": [
        "from llama_index import VectorStoreIndex, StorageContext, ServiceContext\n",
        "from llama_index.embeddings import GeminiEmbedding\n",
        "from llama_index.llms import Gemini\n",
        "from llama_index.vector_stores import QdrantVectorStore\n",
        "from llama_index import StorageContext\n",
        "import qdrant_client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "GmAFELe8k5hs"
      },
      "outputs": [],
      "source": [
        "llm=Gemini(api_key=GOOGLE_API_KEY, temperature=0.1)\n",
        "embed_model = GeminiEmbedding(\n",
        "    model_name=\"models/embedding-001\", api_key=GOOGLE_API_KEY\n",
        ")\n",
        "service_context = ServiceContext.from_defaults(\n",
        "    llm=llm,\n",
        "    #embed_model=\"local:BAAI/bge-small-en-v1.5\"\n",
        "    embed_model = embed_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "kC4USiUTj_SQ"
      },
      "outputs": [],
      "source": [
        "index = VectorStoreIndex.from_documents([document],\n",
        "                                        service_context=service_context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "rM7Cm8zpkGf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b65cffb-064e-4d76-9a36-f785c05e3562"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If the same entity may be a member of more than one subclass of the specialization, then the subclasses are said to be overlapped.\n"
          ]
        }
      ],
      "source": [
        "query_engine = index.as_query_engine()\n",
        "\n",
        "response = query_engine.query(\n",
        "    \"Explain Overlap Constraints\"\n",
        ")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JsvGEz2l_pK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}